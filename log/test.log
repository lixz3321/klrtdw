2022-04-08 09:45:38 [main] INFO  TypeExtractor:1991 - class java.util.LinkedHashMap does not contain a getter for field accessOrder
2022-04-08 09:45:38 [main] INFO  TypeExtractor:1994 - class java.util.LinkedHashMap does not contain a setter for field accessOrder
2022-04-08 09:45:38 [main] INFO  TypeExtractor:2037 - Class class java.util.LinkedHashMap cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2022-04-08 09:45:38 [main] INFO  TypeExtractor:2093 - class org.apache.flink.types.Row is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2022-04-08 09:45:40 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
2022-04-08 09:45:40 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
2022-04-08 09:45:40 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
2022-04-08 09:45:40 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
2022-04-08 09:45:40 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
2022-04-08 09:45:40 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
2022-04-08 09:45:40 [main] INFO  MiniCluster:269 - Starting Flink Mini Cluster
2022-04-08 09:45:40 [main] INFO  MiniCluster:279 - Starting Metrics Registry
2022-04-08 09:45:40 [main] INFO  MetricRegistryImpl:126 - No metrics reporter configured, no metrics will be exposed/reported.
2022-04-08 09:45:40 [main] INFO  MiniCluster:283 - Starting RPC Service(s)
2022-04-08 09:45:40 [main] INFO  AkkaRpcServiceUtils:265 - Trying to start local actor system
2022-04-08 09:45:40 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2022-04-08 09:45:41 [main] INFO  AkkaRpcServiceUtils:298 - Actor system started at akka://flink
2022-04-08 09:45:41 [main] INFO  AkkaRpcServiceUtils:265 - Trying to start local actor system
2022-04-08 09:45:41 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2022-04-08 09:45:42 [main] INFO  AkkaRpcServiceUtils:298 - Actor system started at akka://flink-metrics
2022-04-08 09:45:42 [main] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2022-04-08 09:45:42 [main] INFO  MiniCluster:487 - Starting high-availability services
2022-04-08 09:45:43 [main] INFO  BlobServer:138 - Created BLOB server storage directory C:\Users\lixz\AppData\Local\Temp\blobStore-924acc6f-a471-4adf-90a9-85d27a2bbb0b
2022-04-08 09:45:43 [main] INFO  BlobServer:213 - Started BLOB server at 0.0.0.0:63549 - max concurrent requests: 50 - max backlog: 1000
2022-04-08 09:45:43 [main] INFO  PermanentBlobCache:90 - Created BLOB cache storage directory C:\Users\lixz\AppData\Local\Temp\blobStore-f8568940-d0ee-47a9-ae43-3c3f711fa108
2022-04-08 09:45:43 [main] INFO  TransientBlobCache:90 - Created BLOB cache storage directory C:\Users\lixz\AppData\Local\Temp\blobStore-4a0182f3-efaf-417b-b4e9-49ded11039d8
2022-04-08 09:45:43 [main] INFO  MiniCluster:606 - Starting 1 TaskManger(s)
2022-04-08 09:45:43 [main] INFO  TaskManagerRunner:474 - Starting TaskManager with ResourceID: 56d5ffc3-bff9-4984-92f6-6dcf41c66944
2022-04-08 09:45:43 [main] INFO  TaskManagerServices:441 - Temporary file directory 'C:\Users\lixz\AppData\Local\Temp': total 119 GB, usable 10 GB (8.40% usable)
2022-04-08 09:45:43 [main] INFO  FileChannelManagerImpl:98 - FileChannelManager uses directory C:\Users\lixz\AppData\Local\Temp\flink-io-5a552a1e-0807-4760-aa1d-dfb2787b4b9f for spill files.
2022-04-08 09:45:43 [main] INFO  FileChannelManagerImpl:98 - FileChannelManager uses directory C:\Users\lixz\AppData\Local\Temp\flink-netty-shuffle-bbc671ae-b517-4720-b9f0-f94ff4966e91 for spill files.
2022-04-08 09:45:43 [main] INFO  NetworkBufferPool:145 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2022-04-08 09:45:43 [main] INFO  NettyShuffleEnvironment:328 - Starting the network environment and its components.
2022-04-08 09:45:43 [main] INFO  KvStateService:92 - Starting the kvState service and its components.
2022-04-08 09:45:43 [main] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2022-04-08 09:45:43 [flink-akka.actor.default-dispatcher-3] INFO  DefaultJobLeaderService:123 - Start job leader service.
2022-04-08 09:45:43 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:116 - User file cache uses directory C:\Users\lixz\AppData\Local\Temp\flink-dist-cache-ead78584-c1f7-4d46-a5f2-52397a63137b
2022-04-08 09:45:43 [main] INFO  DispatcherRestEndpoint:139 - Starting rest endpoint.
2022-04-08 09:45:43 [main] INFO  DispatcherRestEndpoint:126 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2022-04-08 09:45:43 [main] WARN  WebMonitorUtils:82 - Log file environment variable 'log.file' is not set.
2022-04-08 09:45:43 [main] WARN  WebMonitorUtils:88 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
2022-04-08 09:45:46 [main] INFO  DispatcherRestEndpoint:250 - Rest endpoint listening at localhost:63602
2022-04-08 09:45:46 [main] INFO  EmbeddedLeaderService:308 - Proposing leadership to contender http://localhost:63602
2022-04-08 09:45:46 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:994 - http://localhost:63602 was granted leadership with leaderSessionID=09a1f143-0c06-4c0f-98dd-fc2388b5831e
2022-04-08 09:45:46 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:256 - Received confirmation of leadership for leader http://localhost:63602 , session=09a1f143-0c06-4c0f-98dd-fc2388b5831e
2022-04-08 09:45:46 [main] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
2022-04-08 09:45:46 [main] INFO  EmbeddedLeaderService:308 - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:234 - Starting the resource manager.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:308 - Proposing leadership to contender LeaderContender: StandaloneResourceManager
2022-04-08 09:45:46 [mini-cluster-io-thread-2] INFO  DefaultDispatcherRunner:107 - DefaultDispatcherRunner was granted leadership with leader id 57fcafd8-5830-4c01-ae9d-7a90d1f4431b. Creating new DispatcherLeaderProcess.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:1230 - ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token 9179fd2156821c1e2075fdc02e024bf6
2022-04-08 09:45:46 [main] INFO  MiniCluster:413 - Flink Mini Cluster started successfully
2022-04-08 09:45:46 [mini-cluster-io-thread-2] INFO  SessionDispatcherLeaderProcess:97 - Start SessionDispatcherLeaderProcess.
2022-04-08 09:45:46 [mini-cluster-io-thread-5] INFO  SessionDispatcherLeaderProcess:117 - Recover all persisted job graphs.
2022-04-08 09:45:46 [mini-cluster-io-thread-5] INFO  SessionDispatcherLeaderProcess:125 - Successfully recovered 0 persisted job graphs.
2022-04-08 09:45:46 [mini-cluster-io-thread-6] INFO  EmbeddedLeaderService:256 - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=2075fdc0-2e02-4bf6-9179-fd2156821c1e
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1293 - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(9179fd2156821c1e2075fdc02e024bf6).
2022-04-08 09:45:46 [mini-cluster-io-thread-5] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
2022-04-08 09:45:46 [mini-cluster-io-thread-5] INFO  EmbeddedLeaderService:256 - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=57fcafd8-5830-4c01-ae9d-7a90d1f4431b
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:162 - Resolved ResourceManager address, beginning registration
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:982 - Registering TaskManager with ResourceID 56d5ffc3-bff9-4984-92f6-6dcf41c66944 (akka://flink/user/rpc/taskmanager_0) at ResourceManager
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:99 - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id 50929326ebc7ab54eef7b1907be54073.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:300 - Received JobGraph submission b4c80fb3f653387dc2b24cb3d08f0812 (collect).
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneDispatcher:362 - Submitting job b4c80fb3f653387dc2b24cb3d08f0812 (collect).
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:308 - Proposing leadership to contender LeaderContender: JobMasterServiceLeadershipRunner
2022-04-08 09:45:46 [jobmanager-future-thread-1] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2022-04-08 09:45:46 [jobmanager-future-thread-1] INFO  JobMaster:289 - Initializing job collect (b4c80fb3f653387dc2b24cb3d08f0812).
2022-04-08 09:45:46 [jobmanager-future-thread-1] INFO  JobMaster:98 - Using restart back off time strategy NoRestartBackoffTimeStrategy for collect (b4c80fb3f653387dc2b24cb3d08f0812).
2022-04-08 09:45:46 [jobmanager-future-thread-1] INFO  JobMaster:159 - Running initialization on master for job collect (b4c80fb3f653387dc2b24cb3d08f0812).
2022-04-08 09:45:46 [jobmanager-future-thread-1] INFO  JobMaster:183 - Successfully ran initialization on master in 0 ms.
2022-04-08 09:45:46 [jobmanager-future-thread-1] INFO  DefaultExecutionTopology:271 - Built 1 pipelined regions in 1 ms
2022-04-08 09:45:46 [jobmanager-future-thread-1] INFO  JobMaster:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@15abe6d0
2022-04-08 09:45:46 [jobmanager-future-thread-1] INFO  JobMaster:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:45:46 [jobmanager-future-thread-1] INFO  CheckpointCoordinator:1532 - No checkpoint found during restore.
2022-04-08 09:45:46 [jobmanager-future-thread-1] INFO  JobMaster:145 - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@5f42fb6c for collect (b4c80fb3f653387dc2b24cb3d08f0812).
2022-04-08 09:45:46 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:256 - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=786f5604-8e13-4b45-a43a-713e4c7d0f44
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:867 - Starting execution of job collect (b4c80fb3f653387dc2b24cb3d08f0812) under job master id a43a713e4c7d0f44786f56048e134b45.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  SourceCoordinator:113 - Starting split enumerator for source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]).
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:183 - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1039 - Job collect (b4c80fb3f653387dc2b24cb3d08f0812) switched from state CREATED to RUNNING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (eea96dfbea1ce830c926cbda63a97ddb) switched from CREATED to SCHEDULED.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (a6e314c7cd07016247185a87b02c7108) switched from CREATED to SCHEDULED.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (67416c0c8987d8e950e418f1eec206af) switched from CREATED to SCHEDULED.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (518589cc9e34139f48119f7a5b8dd020) switched from CREATED to SCHEDULED.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (d1163be00b36e6ef3a6760b2fb526b90) switched from CREATED to SCHEDULED.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (937fc53f5770c6cb9533f247b352652d) switched from CREATED to SCHEDULED.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (93dbab7d9bfe7ee3c268801b4e359572) switched from CREATED to SCHEDULED.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (10a95899eb7c2b13ee44cdb12fb590bb) switched from CREATED to SCHEDULED.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (2ce894f3a79ac31cb57769cc39e8fc1b) switched from CREATED to SCHEDULED.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:1040 - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(9179fd2156821c1e2075fdc02e024bf6)
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:162 - Resolved ResourceManager address, beginning registration
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  ConsumerConfig:347 - ConsumerConfig values: 
	allow.auto.create.topics = false
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [awnx1-cdata-tnode06:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = g1-enumerator-consumer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = g1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:355 - Registering job manager a43a713e4c7d0f44786f56048e134b45@akka://flink/user/rpc/jobmanager_3 for job b4c80fb3f653387dc2b24cb3d08f0812.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:909 - Registered job manager a43a713e4c7d0f44786f56048e134b45@akka://flink/user/rpc/jobmanager_3 for job b4c80fb3f653387dc2b24cb3d08f0812.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:1064 - JobManager successfully registered at ResourceManager, leader id: 9179fd2156821c1e2075fdc02e024bf6.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  DeclarativeSlotManager:263 - Received resource requirements from job b4c80fb3f653387dc2b24cb3d08f0812: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=8}]
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1027 - Receive slot request 943da2c813c73bacb1cc1df1efbc1451 for job b4c80fb3f653387dc2b24cb3d08f0812 from resource manager with leader id 9179fd2156821c1e2075fdc02e024bf6.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1104 - Allocated slot for 943da2c813c73bacb1cc1df1efbc1451.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  DefaultJobLeaderService:188 - Add job b4c80fb3f653387dc2b24cb3d08f0812 for job leader monitoring.
2022-04-08 09:45:46 [mini-cluster-io-thread-17] INFO  DefaultJobLeaderService:346 - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id 786f5604-8e13-4b45-a43a-713e4c7d0f44.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1027 - Receive slot request c4477875168610186ca197945aa5493a for job b4c80fb3f653387dc2b24cb3d08f0812 from resource manager with leader id 9179fd2156821c1e2075fdc02e024bf6.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1104 - Allocated slot for c4477875168610186ca197945aa5493a.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-6] INFO  DefaultJobLeaderService:162 - Resolved JobManager address, beginning registration
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1027 - Receive slot request 49342470b4d9ed6613982dc1a1fa2c5e for job b4c80fb3f653387dc2b24cb3d08f0812 from resource manager with leader id 9179fd2156821c1e2075fdc02e024bf6.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1104 - Allocated slot for 49342470b4d9ed6613982dc1a1fa2c5e.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1027 - Receive slot request dd44d2092aaf7826f3851d6aba2366b7 for job b4c80fb3f653387dc2b24cb3d08f0812 from resource manager with leader id 9179fd2156821c1e2075fdc02e024bf6.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1104 - Allocated slot for dd44d2092aaf7826f3851d6aba2366b7.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1027 - Receive slot request 5e965e89ea2558869065a81949692c6f for job b4c80fb3f653387dc2b24cb3d08f0812 from resource manager with leader id 9179fd2156821c1e2075fdc02e024bf6.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1104 - Allocated slot for 5e965e89ea2558869065a81949692c6f.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1027 - Receive slot request 09b59104177210c02fd79b566f18ba70 for job b4c80fb3f653387dc2b24cb3d08f0812 from resource manager with leader id 9179fd2156821c1e2075fdc02e024bf6.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1104 - Allocated slot for 09b59104177210c02fd79b566f18ba70.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1027 - Receive slot request 0fd88a50d5ac46d386886a4c480b993b for job b4c80fb3f653387dc2b24cb3d08f0812 from resource manager with leader id 9179fd2156821c1e2075fdc02e024bf6.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1104 - Allocated slot for 0fd88a50d5ac46d386886a4c480b993b.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1027 - Receive slot request fdf0b1550a6175751b49bdaaf5dfb8f9 for job b4c80fb3f653387dc2b24cb3d08f0812 from resource manager with leader id 9179fd2156821c1e2075fdc02e024bf6.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1104 - Allocated slot for fdf0b1550a6175751b49bdaaf5dfb8f9.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  DefaultJobLeaderService:413 - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job b4c80fb3f653387dc2b24cb3d08f0812.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1608 - Establish JobManager connection for job b4c80fb3f653387dc2b24cb3d08f0812.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1459 - Offer reserved slots to the leader of job b4c80fb3f653387dc2b24cb3d08f0812.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (eea96dfbea1ce830c926cbda63a97ddb) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (attempt #0) with attempt id eea96dfbea1ce830c926cbda63a97ddb to 56d5ffc3-bff9-4984-92f6-6dcf41c66944 @ 127.0.0.1 (dataPort=-1) with allocation id 49342470b4d9ed6613982dc1a1fa2c5e
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (a6e314c7cd07016247185a87b02c7108) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 49342470b4d9ed6613982dc1a1fa2c5e.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (attempt #0) with attempt id a6e314c7cd07016247185a87b02c7108 to 56d5ffc3-bff9-4984-92f6-6dcf41c66944 @ 127.0.0.1 (dataPort=-1) with allocation id c4477875168610186ca197945aa5493a
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (67416c0c8987d8e950e418f1eec206af) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (attempt #0) with attempt id 67416c0c8987d8e950e418f1eec206af to 56d5ffc3-bff9-4984-92f6-6dcf41c66944 @ 127.0.0.1 (dataPort=-1) with allocation id 943da2c813c73bacb1cc1df1efbc1451
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (518589cc9e34139f48119f7a5b8dd020) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (attempt #0) with attempt id 518589cc9e34139f48119f7a5b8dd020 to 56d5ffc3-bff9-4984-92f6-6dcf41c66944 @ 127.0.0.1 (dataPort=-1) with allocation id dd44d2092aaf7826f3851d6aba2366b7
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (d1163be00b36e6ef3a6760b2fb526b90) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (attempt #0) with attempt id d1163be00b36e6ef3a6760b2fb526b90 to 56d5ffc3-bff9-4984-92f6-6dcf41c66944 @ 127.0.0.1 (dataPort=-1) with allocation id 09b59104177210c02fd79b566f18ba70
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (937fc53f5770c6cb9533f247b352652d) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (attempt #0) with attempt id 937fc53f5770c6cb9533f247b352652d to 56d5ffc3-bff9-4984-92f6-6dcf41c66944 @ 127.0.0.1 (dataPort=-1) with allocation id 5e965e89ea2558869065a81949692c6f
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (93dbab7d9bfe7ee3c268801b4e359572) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (attempt #0) with attempt id 93dbab7d9bfe7ee3c268801b4e359572 to 56d5ffc3-bff9-4984-92f6-6dcf41c66944 @ 127.0.0.1 (dataPort=-1) with allocation id 0fd88a50d5ac46d386886a4c480b993b
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (10a95899eb7c2b13ee44cdb12fb590bb) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (attempt #0) with attempt id 10a95899eb7c2b13ee44cdb12fb590bb to 56d5ffc3-bff9-4984-92f6-6dcf41c66944 @ 127.0.0.1 (dataPort=-1) with allocation id fdf0b1550a6175751b49bdaaf5dfb8f9
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (2ce894f3a79ac31cb57769cc39e8fc1b) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:571 - Deploying Sink: Collect table sink (1/1) (attempt #0) with attempt id 2ce894f3a79ac31cb57769cc39e8fc1b to 56d5ffc3-bff9-4984-92f6-6dcf41c66944 @ 127.0.0.1 (dataPort=-1) with allocation id 49342470b4d9ed6613982dc1a1fa2c5e
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (eea96dfbea1ce830c926cbda63a97ddb), deploy into slot with allocation id 49342470b4d9ed6613982dc1a1fa2c5e.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (eea96dfbea1ce830c926cbda63a97ddb) switched from CREATED to DEPLOYING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot c4477875168610186ca197945aa5493a.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  ConsumerConfig:355 - The configuration 'client.id.prefix' was supplied but isn't a known config.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  ConsumerConfig:355 - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (eea96dfbea1ce830c926cbda63a97ddb) [DEPLOYING].
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (a6e314c7cd07016247185a87b02c7108), deploy into slot with allocation id c4477875168610186ca197945aa5493a.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 943da2c813c73bacb1cc1df1efbc1451.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (a6e314c7cd07016247185a87b02c7108) switched from CREATED to DEPLOYING.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (a6e314c7cd07016247185a87b02c7108) [DEPLOYING].
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (67416c0c8987d8e950e418f1eec206af), deploy into slot with allocation id 943da2c813c73bacb1cc1df1efbc1451.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (67416c0c8987d8e950e418f1eec206af) switched from CREATED to DEPLOYING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot dd44d2092aaf7826f3851d6aba2366b7.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (67416c0c8987d8e950e418f1eec206af) [DEPLOYING].
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (518589cc9e34139f48119f7a5b8dd020), deploy into slot with allocation id dd44d2092aaf7826f3851d6aba2366b7.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:117 - Kafka version: 2.4.1
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:118 - Kafka commitId: c57222ae8cd7866b
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 09b59104177210c02fd79b566f18ba70.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:119 - Kafka startTimeMs: 1649382346629
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (518589cc9e34139f48119f7a5b8dd020) switched from CREATED to DEPLOYING.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (518589cc9e34139f48119f7a5b8dd020) [DEPLOYING].
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AdminClientConfig:347 - AdminClientConfig values: 
	bootstrap.servers = [awnx1-cdata-tnode06:6667]
	client.dns.lookup = default
	client.id = g1-enumerator-admin-client
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (d1163be00b36e6ef3a6760b2fb526b90), deploy into slot with allocation id 09b59104177210c02fd79b566f18ba70.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 5e965e89ea2558869065a81949692c6f.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (d1163be00b36e6ef3a6760b2fb526b90) switched from CREATED to DEPLOYING.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (d1163be00b36e6ef3a6760b2fb526b90) [DEPLOYING].
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (937fc53f5770c6cb9533f247b352652d), deploy into slot with allocation id 5e965e89ea2558869065a81949692c6f.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 0fd88a50d5ac46d386886a4c480b993b.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (937fc53f5770c6cb9533f247b352652d) switched from CREATED to DEPLOYING.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (937fc53f5770c6cb9533f247b352652d) [DEPLOYING].
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (93dbab7d9bfe7ee3c268801b4e359572), deploy into slot with allocation id 0fd88a50d5ac46d386886a4c480b993b.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (93dbab7d9bfe7ee3c268801b4e359572) switched from CREATED to DEPLOYING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot fdf0b1550a6175751b49bdaaf5dfb8f9.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (93dbab7d9bfe7ee3c268801b4e359572) [DEPLOYING].
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (10a95899eb7c2b13ee44cdb12fb590bb), deploy into slot with allocation id fdf0b1550a6175751b49bdaaf5dfb8f9.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 49342470b4d9ed6613982dc1a1fa2c5e.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (10a95899eb7c2b13ee44cdb12fb590bb) switched from CREATED to DEPLOYING.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (10a95899eb7c2b13ee44cdb12fb590bb) [DEPLOYING].
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@65eecddf
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@d078e51
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@768fdbe5
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@7755e5ba
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@a6f9ce1
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@2f4346ce
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@478011bb
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6ba9dd14
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Sink: Collect table sink (1/1)#0 (2ce894f3a79ac31cb57769cc39e8fc1b), deploy into slot with allocation id 49342470b4d9ed6613982dc1a1fa2c5e.
2022-04-08 09:45:46 [Sink: Collect table sink (1/1)#0] INFO  Task:1067 - Sink: Collect table sink (1/1)#0 (2ce894f3a79ac31cb57769cc39e8fc1b) switched from CREATED to DEPLOYING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 0fd88a50d5ac46d386886a4c480b993b.
2022-04-08 09:45:46 [Sink: Collect table sink (1/1)#0] INFO  Task:626 - Loading JAR files for task Sink: Collect table sink (1/1)#0 (2ce894f3a79ac31cb57769cc39e8fc1b) [DEPLOYING].
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot fdf0b1550a6175751b49bdaaf5dfb8f9.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot c4477875168610186ca197945aa5493a.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 49342470b4d9ed6613982dc1a1fa2c5e.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 5e965e89ea2558869065a81949692c6f.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 09b59104177210c02fd79b566f18ba70.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 943da2c813c73bacb1cc1df1efbc1451.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot dd44d2092aaf7826f3851d6aba2366b7.
2022-04-08 09:45:46 [Sink: Collect table sink (1/1)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@47f2181
2022-04-08 09:45:46 [Sink: Collect table sink (1/1)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (67416c0c8987d8e950e418f1eec206af) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (10a95899eb7c2b13ee44cdb12fb590bb) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (937fc53f5770c6cb9533f247b352652d) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (d1163be00b36e6ef3a6760b2fb526b90) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [Sink: Collect table sink (1/1)#0] INFO  Task:1067 - Sink: Collect table sink (1/1)#0 (2ce894f3a79ac31cb57769cc39e8fc1b) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (93dbab7d9bfe7ee3c268801b4e359572) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (a6e314c7cd07016247185a87b02c7108) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (518589cc9e34139f48119f7a5b8dd020) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (eea96dfbea1ce830c926cbda63a97ddb) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'key.deserializer' was supplied but isn't a known config.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'value.deserializer' was supplied but isn't a known config.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'group.id' was supplied but isn't a known config.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'client.id.prefix' was supplied but isn't a known config.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:117 - Kafka version: 2.4.1
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:118 - Kafka commitId: c57222ae8cd7866b
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (67416c0c8987d8e950e418f1eec206af) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:119 - Kafka startTimeMs: 1649382346698
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  KafkaSourceEnumerator:157 - Starting the KafkaSourceEnumerator for consumer group g1 without periodic partition discovery.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (10a95899eb7c2b13ee44cdb12fb590bb) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (937fc53f5770c6cb9533f247b352652d) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (d1163be00b36e6ef3a6760b2fb526b90) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (2ce894f3a79ac31cb57769cc39e8fc1b) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (93dbab7d9bfe7ee3c268801b4e359572) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (a6e314c7cd07016247185a87b02c7108) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (518589cc9e34139f48119f7a5b8dd020) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (eea96dfbea1ce830c926cbda63a97ddb) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:45:46 [Sink: Collect table sink (1/1)#0] INFO  CollectSinkFunction:205 - Initializing collect sink state with offset = 0, buffered results bytes = 0
2022-04-08 09:45:46 [Sink: Collect table sink (1/1)#0] INFO  CollectSinkFunction:258 - Collect sink server established, address = localhost/127.0.0.1:63611
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  CollectSinkOperatorCoordinator:92 - Received sink socket server address: localhost/127.0.0.1:63611
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (937fc53f5770c6cb9533f247b352652d) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 1 @ 
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (67416c0c8987d8e950e418f1eec206af) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 5 @ 
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (a6e314c7cd07016247185a87b02c7108) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 7 @ 
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (937fc53f5770c6cb9533f247b352652d) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 4 @ 
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 0 @ 
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (67416c0c8987d8e950e418f1eec206af) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 2 @ 
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 3 @ 
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (a6e314c7cd07016247185a87b02c7108) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 6 @ 
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (518589cc9e34139f48119f7a5b8dd020) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (d1163be00b36e6ef3a6760b2fb526b90) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (eea96dfbea1ce830c926cbda63a97ddb) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (10a95899eb7c2b13ee44cdb12fb590bb) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:46 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (93dbab7d9bfe7ee3c268801b4e359572) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (518589cc9e34139f48119f7a5b8dd020) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (d1163be00b36e6ef3a6760b2fb526b90) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:46 [Sink: Collect table sink (1/1)#0] INFO  Task:1067 - Sink: Collect table sink (1/1)#0 (2ce894f3a79ac31cb57769cc39e8fc1b) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (eea96dfbea1ce830c926cbda63a97ddb) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (10a95899eb7c2b13ee44cdb12fb590bb) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (93dbab7d9bfe7ee3c268801b4e359572) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:46 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (2ce894f3a79ac31cb57769cc39e8fc1b) switched from INITIALIZING to RUNNING.
2022-04-08 09:45:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])-worker-thread-1] INFO  TopicListSubscriber:68 - The following partitions have been added to the Kafka cluster. [test1-0]
2022-04-08 09:45:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  KafkaSourceEnumerator:299 - Assigning splits to readers {1=[[Partition: test1-0, StartingOffset: -1, StoppingOffset: -9223372036854775808]]}
2022-04-08 09:45:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SourceReaderBase:220 - Adding split(s) to reader: [[Partition: test1-0, StartingOffset: -1, StoppingOffset: -9223372036854775808]]
2022-04-08 09:45:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  ConsumerConfig:347 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [awnx1-cdata-tnode06:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = g1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = g1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-04-08 09:45:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] WARN  ConsumerConfig:355 - The configuration 'client.id.prefix' was supplied but isn't a known config.
2022-04-08 09:45:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] WARN  ConsumerConfig:355 - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2022-04-08 09:45:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  AppInfoParser:117 - Kafka version: 2.4.1
2022-04-08 09:45:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  AppInfoParser:118 - Kafka commitId: c57222ae8cd7866b
2022-04-08 09:45:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  AppInfoParser:119 - Kafka startTimeMs: 1649382347378
2022-04-08 09:45:47 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SplitFetcher:100 - Starting split fetcher 0
2022-04-08 09:45:47 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  KafkaConsumer:1123 - [Consumer clientId=g1-1, groupId=g1] Subscribed to partition(s): test1-0
2022-04-08 09:45:47 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SubscriptionState:564 - [Consumer clientId=g1-1, groupId=g1] Seeking to LATEST offset of partition test1-0
2022-04-08 09:45:47 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Metadata:259 - [Consumer clientId=g1-1, groupId=g1] Cluster ID: 5yVv1a4oRyO2KnAySdX1qw
2022-04-08 09:45:47 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SubscriptionState:381 - [Consumer clientId=g1-1, groupId=g1] Resetting offset for partition test1-0 to offset 111.
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SourceReaderBase:244 - Closing Source Reader.
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SplitFetcher:190 - Shutting down split fetcher 0
2022-04-08 09:45:53 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SplitFetcher:113 - Split fetcher 0 exited.
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] WARN  Task:1074 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (a6e314c7cd07016247185a87b02c7108) switched from RUNNING to FAILED with failure cause: java.lang.RuntimeException: Row arity of from (4) does not match this serializer's field length (3).
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copyPositionBased(RowSerializer.java:153)
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:142)
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:72)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:69)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26)
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:50)
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:28)
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:50)
	at kl.tmp.App2$1.flatMap(App2.java:92)
	at kl.tmp.App2$1.flatMap(App2.java:88)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:71)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26)
	at org.apache.flink.streaming.runtime.tasks.SourceOperatorStreamTask$AsyncDataOutputToOutput.emitRecord(SourceOperatorStreamTask.java:188)
	at org.apache.flink.streaming.api.operators.source.SourceOutputWithWatermarks.collect(SourceOutputWithWatermarks.java:110)
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:36)
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:27)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:128)
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:305)
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:69)
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:66)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:423)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:204)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:684)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.executeInvoke(StreamTask.java:639)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runWithCleanUpOnFail(StreamTask.java:650)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:623)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:779)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:566)
	at java.lang.Thread.run(Thread.java:748)

2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:893 - Freeing task resources for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (a6e314c7cd07016247185a87b02c7108).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state FAILED to JobManager for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 a6e314c7cd07016247185a87b02c7108.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1446 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (a6e314c7cd07016247185a87b02c7108) switched from RUNNING to FAILED on 56d5ffc3-bff9-4984-92f6-6dcf41c66944 @ 127.0.0.1 (dataPort=-1).
java.lang.RuntimeException: Row arity of from (4) does not match this serializer's field length (3).
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copyPositionBased(RowSerializer.java:153) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:142) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:72) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:69) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:50) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:28) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:50) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at kl.tmp.App2$1.flatMap(App2.java:92) ~[classes/:?]
	at kl.tmp.App2$1.flatMap(App2.java:88) ~[classes/:?]
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:71) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.SourceOperatorStreamTask$AsyncDataOutputToOutput.emitRecord(SourceOperatorStreamTask.java:188) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.source.SourceOutputWithWatermarks.collect(SourceOutputWithWatermarks.java:110) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:36) ~[flink-connector-kafka_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:27) ~[flink-connector-kafka_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:128) ~[flink-connector-base-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:305) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:69) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:66) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:423) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:204) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:684) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.executeInvoke(StreamTask.java:639) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runWithCleanUpOnFail(StreamTask.java:650) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:623) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:779) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:566) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  DeclarativeSlotManager:263 - Received resource requirements from job b4c80fb3f653387dc2b24cb3d08f0812: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=7}]
2022-04-08 09:45:53 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:205 - Removing registered reader after failure for subtask 1 of source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  RestartPipelinedRegionFailoverStrategy:115 - Calculating tasks to restart to recover the failed task cbc357ccb763df2852fee8c4fc7d55f2_1.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  RestartPipelinedRegionFailoverStrategy:152 - 9 tasks should be restarted to recover the failed task cbc357ccb763df2852fee8c4fc7d55f2_1. 
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1039 - Job collect (b4c80fb3f653387dc2b24cb3d08f0812) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:138) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:82) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:216) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:206) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:197) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:682) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:79) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:435) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at sun.reflect.GeneratedMethodAccessor17.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_181]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_181]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:77) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) [scala-library-2.11.12.jar:?]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) [scala-library-2.11.12.jar:?]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) [scala-library-2.11.12.jar:?]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) [scala-library-2.11.12.jar:?]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [akka-actor_2.11-2.5.21.jar:2.5.21]
Caused by: java.lang.RuntimeException: Row arity of from (4) does not match this serializer's field length (3).
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copyPositionBased(RowSerializer.java:153) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:142) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:72) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:69) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:50) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:28) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:50) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at kl.tmp.App2$1.flatMap(App2.java:92) ~[classes/:?]
	at kl.tmp.App2$1.flatMap(App2.java:88) ~[classes/:?]
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:71) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.SourceOperatorStreamTask$AsyncDataOutputToOutput.emitRecord(SourceOperatorStreamTask.java:188) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.source.SourceOutputWithWatermarks.collect(SourceOutputWithWatermarks.java:110) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:36) ~[flink-connector-kafka_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:27) ~[flink-connector-kafka_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:128) ~[flink-connector-base-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:305) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:69) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:66) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:423) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:204) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:684) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.executeInvoke(StreamTask.java:639) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runWithCleanUpOnFail(StreamTask.java:650) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:623) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:779) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:566) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (eea96dfbea1ce830c926cbda63a97ddb) switched from RUNNING to CANCELING.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1102 - Attempting to cancel task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (eea96dfbea1ce830c926cbda63a97ddb).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (eea96dfbea1ce830c926cbda63a97ddb) switched from RUNNING to CANCELING.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1168 - Triggering cancellation of task code Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (eea96dfbea1ce830c926cbda63a97ddb).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (67416c0c8987d8e950e418f1eec206af) switched from RUNNING to CANCELING.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (518589cc9e34139f48119f7a5b8dd020) switched from RUNNING to CANCELING.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (d1163be00b36e6ef3a6760b2fb526b90) switched from RUNNING to CANCELING.
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  SourceReaderBase:244 - Closing Source Reader.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (937fc53f5770c6cb9533f247b352652d) switched from RUNNING to CANCELING.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (93dbab7d9bfe7ee3c268801b4e359572) switched from RUNNING to CANCELING.
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (eea96dfbea1ce830c926cbda63a97ddb) switched from CANCELING to CANCELED.
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:893 - Freeing task resources for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (eea96dfbea1ce830c926cbda63a97ddb).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1102 - Attempting to cancel task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (67416c0c8987d8e950e418f1eec206af).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (10a95899eb7c2b13ee44cdb12fb590bb) switched from RUNNING to CANCELING.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (67416c0c8987d8e950e418f1eec206af) switched from RUNNING to CANCELING.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (2ce894f3a79ac31cb57769cc39e8fc1b) switched from RUNNING to CANCELING.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1168 - Triggering cancellation of task code Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (67416c0c8987d8e950e418f1eec206af).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1102 - Attempting to cancel task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (518589cc9e34139f48119f7a5b8dd020).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (518589cc9e34139f48119f7a5b8dd020) switched from RUNNING to CANCELING.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1168 - Triggering cancellation of task code Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (518589cc9e34139f48119f7a5b8dd020).
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  SourceReaderBase:244 - Closing Source Reader.
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (67416c0c8987d8e950e418f1eec206af) switched from CANCELING to CANCELED.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1102 - Attempting to cancel task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (d1163be00b36e6ef3a6760b2fb526b90).
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:893 - Freeing task resources for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (67416c0c8987d8e950e418f1eec206af).
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  SourceReaderBase:244 - Closing Source Reader.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (d1163be00b36e6ef3a6760b2fb526b90) switched from RUNNING to CANCELING.
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (518589cc9e34139f48119f7a5b8dd020) switched from CANCELING to CANCELED.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1168 - Triggering cancellation of task code Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (d1163be00b36e6ef3a6760b2fb526b90).
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:893 - Freeing task resources for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (518589cc9e34139f48119f7a5b8dd020).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1102 - Attempting to cancel task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (937fc53f5770c6cb9533f247b352652d).
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  SourceReaderBase:244 - Closing Source Reader.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (937fc53f5770c6cb9533f247b352652d) switched from RUNNING to CANCELING.
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (d1163be00b36e6ef3a6760b2fb526b90) switched from CANCELING to CANCELED.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1168 - Triggering cancellation of task code Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (937fc53f5770c6cb9533f247b352652d).
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:893 - Freeing task resources for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (d1163be00b36e6ef3a6760b2fb526b90).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1102 - Attempting to cancel task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (93dbab7d9bfe7ee3c268801b4e359572).
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  SourceReaderBase:244 - Closing Source Reader.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (93dbab7d9bfe7ee3c268801b4e359572) switched from RUNNING to CANCELING.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1168 - Triggering cancellation of task code Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (93dbab7d9bfe7ee3c268801b4e359572).
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (937fc53f5770c6cb9533f247b352652d) switched from CANCELING to CANCELED.
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:893 - Freeing task resources for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (937fc53f5770c6cb9533f247b352652d).
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  SourceReaderBase:244 - Closing Source Reader.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 eea96dfbea1ce830c926cbda63a97ddb.
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (93dbab7d9bfe7ee3c268801b4e359572) switched from CANCELING to CANCELED.
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:893 - Freeing task resources for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (93dbab7d9bfe7ee3c268801b4e359572).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (eea96dfbea1ce830c926cbda63a97ddb) switched from CANCELING to CANCELED.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1102 - Attempting to cancel task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (10a95899eb7c2b13ee44cdb12fb590bb).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (10a95899eb7c2b13ee44cdb12fb590bb) switched from RUNNING to CANCELING.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1168 - Triggering cancellation of task code Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (10a95899eb7c2b13ee44cdb12fb590bb).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1102 - Attempting to cancel task Sink: Collect table sink (1/1)#0 (2ce894f3a79ac31cb57769cc39e8fc1b).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1067 - Sink: Collect table sink (1/1)#0 (2ce894f3a79ac31cb57769cc39e8fc1b) switched from RUNNING to CANCELING.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  Task:1168 - Triggering cancellation of task code Sink: Collect table sink (1/1)#0 (2ce894f3a79ac31cb57769cc39e8fc1b).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 67416c0c8987d8e950e418f1eec206af.
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  SourceReaderBase:244 - Closing Source Reader.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 518589cc9e34139f48119f7a5b8dd020.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (67416c0c8987d8e950e418f1eec206af) switched from CANCELING to CANCELED.
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (10a95899eb7c2b13ee44cdb12fb590bb) switched from CANCELING to CANCELED.
2022-04-08 09:45:53 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:893 - Freeing task resources for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (10a95899eb7c2b13ee44cdb12fb590bb).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 d1163be00b36e6ef3a6760b2fb526b90.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (518589cc9e34139f48119f7a5b8dd020) switched from CANCELING to CANCELED.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  DeclarativeSlotManager:263 - Received resource requirements from job b4c80fb3f653387dc2b24cb3d08f0812: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=6}]
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 937fc53f5770c6cb9533f247b352652d.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 93dbab7d9bfe7ee3c268801b4e359572.
2022-04-08 09:45:53 [Sink: Collect table sink (1/1)#0] INFO  Task:1067 - Sink: Collect table sink (1/1)#0 (2ce894f3a79ac31cb57769cc39e8fc1b) switched from CANCELING to CANCELED.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (d1163be00b36e6ef3a6760b2fb526b90) switched from CANCELING to CANCELED.
2022-04-08 09:45:53 [Sink: Collect table sink (1/1)#0] INFO  Task:893 - Freeing task resources for Sink: Collect table sink (1/1)#0 (2ce894f3a79ac31cb57769cc39e8fc1b).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 10a95899eb7c2b13ee44cdb12fb590bb.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  DeclarativeSlotManager:263 - Received resource requirements from job b4c80fb3f653387dc2b24cb3d08f0812: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=5}]
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state CANCELED to JobManager for task Sink: Collect table sink (1/1)#0 2ce894f3a79ac31cb57769cc39e8fc1b.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  DeclarativeSlotManager:263 - Received resource requirements from job b4c80fb3f653387dc2b24cb3d08f0812: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=4}]
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (937fc53f5770c6cb9533f247b352652d) switched from CANCELING to CANCELED.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  DeclarativeSlotManager:263 - Received resource requirements from job b4c80fb3f653387dc2b24cb3d08f0812: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=3}]
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (93dbab7d9bfe7ee3c268801b4e359572) switched from CANCELING to CANCELED.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  DeclarativeSlotManager:263 - Received resource requirements from job b4c80fb3f653387dc2b24cb3d08f0812: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=2}]
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (10a95899eb7c2b13ee44cdb12fb590bb) switched from CANCELING to CANCELED.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  DeclarativeSlotManager:263 - Received resource requirements from job b4c80fb3f653387dc2b24cb3d08f0812: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (2ce894f3a79ac31cb57769cc39e8fc1b) switched from CANCELING to CANCELED.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  DeclarativeSlotManager:261 - Clearing resource requirements of job b4c80fb3f653387dc2b24cb3d08f0812
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  ExecutionGraph:1039 - Job collect (b4c80fb3f653387dc2b24cb3d08f0812) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:138) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:82) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:216) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:206) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:197) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:682) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:79) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:435) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at sun.reflect.GeneratedMethodAccessor17.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_181]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_181]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:77) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) [scala-library-2.11.12.jar:?]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) [scala-library-2.11.12.jar:?]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) [scala-library-2.11.12.jar:?]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) [scala-library-2.11.12.jar:?]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [akka-actor_2.11-2.5.21.jar:2.5.21]
Caused by: java.lang.RuntimeException: Row arity of from (4) does not match this serializer's field length (3).
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copyPositionBased(RowSerializer.java:153) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:142) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:72) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:69) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:50) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:28) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:50) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at kl.tmp.App2$1.flatMap(App2.java:92) ~[classes/:?]
	at kl.tmp.App2$1.flatMap(App2.java:88) ~[classes/:?]
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:71) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.SourceOperatorStreamTask$AsyncDataOutputToOutput.emitRecord(SourceOperatorStreamTask.java:188) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.source.SourceOutputWithWatermarks.collect(SourceOutputWithWatermarks.java:110) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:36) ~[flink-connector-kafka_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:27) ~[flink-connector-kafka_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:128) ~[flink-connector-base-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:305) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:69) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:66) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:423) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:204) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:684) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.executeInvoke(StreamTask.java:639) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runWithCleanUpOnFail(StreamTask.java:650) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:623) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:779) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:566) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  CheckpointCoordinator:406 - Stopping checkpoint coordinator for job b4c80fb3f653387dc2b24cb3d08f0812.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] WARN  TaskManagerLocation:240 - No hostname could be resolved for the IP address 127.0.0.1, using IP address as host name. Local input split assignment (such as for HDFS files) may be impacted.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  StandaloneCompletedCheckpointStore:96 - Shutting down
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  MiniCluster:530 - Shutting down Flink Mini Cluster
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:839 - Job b4c80fb3f653387dc2b24cb3d08f0812 reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:138)
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:82)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:216)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:206)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:197)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:682)
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:79)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:435)
	at sun.reflect.GeneratedMethodAccessor17.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212)
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:77)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.RuntimeException: Row arity of from (4) does not match this serializer's field length (3).
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copyPositionBased(RowSerializer.java:153)
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:142)
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:72)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:69)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26)
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:50)
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:28)
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:50)
	at kl.tmp.App2$1.flatMap(App2.java:92)
	at kl.tmp.App2$1.flatMap(App2.java:88)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:71)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26)
	at org.apache.flink.streaming.runtime.tasks.SourceOperatorStreamTask$AsyncDataOutputToOutput.emitRecord(SourceOperatorStreamTask.java:188)
	at org.apache.flink.streaming.api.operators.source.SourceOutputWithWatermarks.collect(SourceOutputWithWatermarks.java:110)
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:36)
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:27)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:128)
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:305)
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:69)
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:66)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:423)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:204)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:684)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.executeInvoke(StreamTask.java:639)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runWithCleanUpOnFail(StreamTask.java:650)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:623)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:779)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:566)
	at java.lang.Thread.run(Thread.java:748)
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  TaskExecutor:434 - Stopping TaskExecutor akka://flink/user/rpc/taskmanager_0.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  TaskExecutor:1386 - Close ResourceManager connection e54676714ffc80c5b72ae7a91d1d33e0.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  DispatcherRestEndpoint:309 - Shutting down rest endpoint.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  StandaloneResourceManager:1083 - Closing TaskExecutor connection 56d5ffc3-bff9-4984-92f6-6dcf41c66944 because: The TaskExecutor is shutting down.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  TaskExecutor:1652 - Close JobManager connection for job b4c80fb3f653387dc2b24cb3d08f0812.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:395 - Stopping the JobMaster for job collect(b4c80fb3f653387dc2b24cb3d08f0812).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  TaskSlotTableImpl:439 - Free slot TaskSlot(index:6, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 0fd88a50d5ac46d386886a4c480b993b, jobId: b4c80fb3f653387dc2b24cb3d08f0812).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  TaskSlotTableImpl:439 - Free slot TaskSlot(index:7, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: fdf0b1550a6175751b49bdaaf5dfb8f9, jobId: b4c80fb3f653387dc2b24cb3d08f0812).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  TaskSlotTableImpl:439 - Free slot TaskSlot(index:1, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: c4477875168610186ca197945aa5493a, jobId: b4c80fb3f653387dc2b24cb3d08f0812).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  TaskSlotTableImpl:439 - Free slot TaskSlot(index:2, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 49342470b4d9ed6613982dc1a1fa2c5e, jobId: b4c80fb3f653387dc2b24cb3d08f0812).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  TaskSlotTableImpl:439 - Free slot TaskSlot(index:4, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 5e965e89ea2558869065a81949692c6f, jobId: b4c80fb3f653387dc2b24cb3d08f0812).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  TaskSlotTableImpl:439 - Free slot TaskSlot(index:5, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 09b59104177210c02fd79b566f18ba70, jobId: b4c80fb3f653387dc2b24cb3d08f0812).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  TaskSlotTableImpl:439 - Free slot TaskSlot(index:0, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 943da2c813c73bacb1cc1df1efbc1451, jobId: b4c80fb3f653387dc2b24cb3d08f0812).
2022-04-08 09:45:53 [Thread-8] INFO  SourceCoordinator:146 - Closing SourceCoordinator for source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  TaskSlotTableImpl:439 - Free slot TaskSlot(index:3, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: dd44d2092aaf7826f3851d6aba2366b7, jobId: b4c80fb3f653387dc2b24cb3d08f0812).
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  DefaultDeclarativeSlotPool:474 - Releasing slot [0fd88a50d5ac46d386886a4c480b993b].
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  DefaultJobLeaderService:136 - Stop job leader service.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  DefaultDeclarativeSlotPool:474 - Releasing slot [fdf0b1550a6175751b49bdaaf5dfb8f9].
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  TaskExecutorLocalStateStoresManager:231 - Shutting down TaskExecutorLocalStateStoresManager.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  DefaultDeclarativeSlotPool:474 - Releasing slot [c4477875168610186ca197945aa5493a].
2022-04-08 09:45:53 [Thread-8] INFO  SourceCoordinator:160 - Source coordinator for source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) closed.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  DefaultDeclarativeSlotPool:474 - Releasing slot [49342470b4d9ed6613982dc1a1fa2c5e].
2022-04-08 09:45:53 [ForkJoinPool.commonPool-worker-2] INFO  DispatcherRestEndpoint:970 - Removing cache directory C:\Users\lixz\AppData\Local\Temp\flink-web-ui
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  DefaultDeclarativeSlotPool:474 - Releasing slot [5e965e89ea2558869065a81949692c6f].
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  DefaultDeclarativeSlotPool:474 - Releasing slot [09b59104177210c02fd79b566f18ba70].
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  DefaultDeclarativeSlotPool:474 - Releasing slot [943da2c813c73bacb1cc1df1efbc1451].
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  DefaultDeclarativeSlotPool:474 - Releasing slot [dd44d2092aaf7826f3851d6aba2366b7].
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:1124 - Close ResourceManager connection e54676714ffc80c5b72ae7a91d1d33e0: Stopping JobMaster for job collect(b4c80fb3f653387dc2b24cb3d08f0812)..
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  StandaloneResourceManager:1047 - Disconnect job manager a43a713e4c7d0f44786f56048e134b45@akka://flink/user/rpc/jobmanager_3 for job b4c80fb3f653387dc2b24cb3d08f0812 from the resource manager.
2022-04-08 09:45:53 [ForkJoinPool.commonPool-worker-2] INFO  DispatcherRestEndpoint:317 - Shut down complete.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  StandaloneResourceManager:629 - Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  DispatcherResourceManagerComponent:162 - Closing components.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-6] INFO  SessionDispatcherLeaderProcess:134 - Stopping SessionDispatcherLeaderProcess.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:265 - Stopping dispatcher akka://flink/user/rpc/dispatcher_2.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:793 - Stopping all currently running jobs of dispatcher akka://flink/user/rpc/dispatcher_2.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  DeclarativeSlotManager:240 - Closing the slot manager.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-7] INFO  DeclarativeSlotManager:212 - Suspending the slot manager.
2022-04-08 09:45:53 [mini-cluster-io-thread-21] INFO  StandaloneDispatcher:277 - Stopped dispatcher akka://flink/user/rpc/dispatcher_2.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  FileChannelManagerImpl:149 - FileChannelManager removed spill file directory C:\Users\lixz\AppData\Local\Temp\flink-io-5a552a1e-0807-4760-aa1d-dfb2787b4b9f
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  NettyShuffleEnvironment:347 - Shutting down the network environment and its components.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  FileChannelManagerImpl:149 - FileChannelManager removed spill file directory C:\Users\lixz\AppData\Local\Temp\flink-netty-shuffle-bbc671ae-b517-4720-b9f0-f94ff4966e91
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  KvStateService:122 - Shutting down the kvState service and its components.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  DefaultJobLeaderService:136 - Stop job leader service.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  FileCache:160 - removed file cache directory C:\Users\lixz\AppData\Local\Temp\flink-dist-cache-ead78584-c1f7-4d46-a5f2-52397a63137b
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-8] INFO  TaskExecutor:479 - Stopped TaskExecutor akka://flink/user/rpc/taskmanager_0.
2022-04-08 09:45:53 [AkkaRpcService-Supervisor-Termination-Future-Executor-thread-1] INFO  AkkaRpcService:403 - Stopping Akka RPC service.
2022-04-08 09:45:53 [flink-metrics-2] INFO  AkkaRpcService:403 - Stopping Akka RPC service.
2022-04-08 09:45:53 [flink-metrics-2] INFO  AkkaRpcService:427 - Stopped Akka RPC service.
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  PermanentBlobCache:240 - Shutting down BLOB cache
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  TransientBlobCache:240 - Shutting down BLOB cache
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  BlobServer:345 - Stopped BLOB server at 0.0.0.0:63549
2022-04-08 09:45:53 [flink-akka.actor.default-dispatcher-4] INFO  AkkaRpcService:427 - Stopped Akka RPC service.
2022-04-08 09:48:38 [main] INFO  TypeExtractor:1991 - class java.util.LinkedHashMap does not contain a getter for field accessOrder
2022-04-08 09:48:38 [main] INFO  TypeExtractor:1994 - class java.util.LinkedHashMap does not contain a setter for field accessOrder
2022-04-08 09:48:38 [main] INFO  TypeExtractor:2037 - Class class java.util.LinkedHashMap cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2022-04-08 09:48:38 [main] INFO  TypeExtractor:2093 - class org.apache.flink.types.Row is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2022-04-08 09:48:40 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
2022-04-08 09:48:40 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
2022-04-08 09:48:40 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
2022-04-08 09:48:40 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
2022-04-08 09:48:40 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
2022-04-08 09:48:40 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
2022-04-08 09:48:40 [main] INFO  MiniCluster:269 - Starting Flink Mini Cluster
2022-04-08 09:48:40 [main] INFO  MiniCluster:279 - Starting Metrics Registry
2022-04-08 09:48:40 [main] INFO  MetricRegistryImpl:126 - No metrics reporter configured, no metrics will be exposed/reported.
2022-04-08 09:48:40 [main] INFO  MiniCluster:283 - Starting RPC Service(s)
2022-04-08 09:48:40 [main] INFO  AkkaRpcServiceUtils:265 - Trying to start local actor system
2022-04-08 09:48:41 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2022-04-08 09:48:41 [main] INFO  AkkaRpcServiceUtils:298 - Actor system started at akka://flink
2022-04-08 09:48:41 [main] INFO  AkkaRpcServiceUtils:265 - Trying to start local actor system
2022-04-08 09:48:41 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2022-04-08 09:48:42 [main] INFO  AkkaRpcServiceUtils:298 - Actor system started at akka://flink-metrics
2022-04-08 09:48:42 [main] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2022-04-08 09:48:42 [main] INFO  MiniCluster:487 - Starting high-availability services
2022-04-08 09:48:43 [main] INFO  BlobServer:138 - Created BLOB server storage directory C:\Users\lixz\AppData\Local\Temp\blobStore-48186ecc-b2fb-4e8b-b211-0f25278acb00
2022-04-08 09:48:43 [main] INFO  BlobServer:213 - Started BLOB server at 0.0.0.0:63943 - max concurrent requests: 50 - max backlog: 1000
2022-04-08 09:48:43 [main] INFO  PermanentBlobCache:90 - Created BLOB cache storage directory C:\Users\lixz\AppData\Local\Temp\blobStore-b97fa754-3bdf-448d-8da5-3274d2cca28f
2022-04-08 09:48:43 [main] INFO  TransientBlobCache:90 - Created BLOB cache storage directory C:\Users\lixz\AppData\Local\Temp\blobStore-ce00d287-2066-4dc7-bf10-392302582f85
2022-04-08 09:48:43 [main] INFO  MiniCluster:606 - Starting 1 TaskManger(s)
2022-04-08 09:48:43 [main] INFO  TaskManagerRunner:474 - Starting TaskManager with ResourceID: 0eaf7902-ad14-4fe7-b3a4-2cbeddb259ef
2022-04-08 09:48:43 [main] INFO  TaskManagerServices:441 - Temporary file directory 'C:\Users\lixz\AppData\Local\Temp': total 119 GB, usable 10 GB (8.40% usable)
2022-04-08 09:48:43 [main] INFO  FileChannelManagerImpl:98 - FileChannelManager uses directory C:\Users\lixz\AppData\Local\Temp\flink-io-edb3a558-e3f3-4b12-96ab-064fd3326d45 for spill files.
2022-04-08 09:48:43 [main] INFO  FileChannelManagerImpl:98 - FileChannelManager uses directory C:\Users\lixz\AppData\Local\Temp\flink-netty-shuffle-23516dab-f56c-481c-9948-e4f226d61b08 for spill files.
2022-04-08 09:48:43 [main] INFO  NetworkBufferPool:145 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2022-04-08 09:48:44 [main] INFO  NettyShuffleEnvironment:328 - Starting the network environment and its components.
2022-04-08 09:48:44 [main] INFO  KvStateService:92 - Starting the kvState service and its components.
2022-04-08 09:48:44 [main] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2022-04-08 09:48:44 [flink-akka.actor.default-dispatcher-3] INFO  DefaultJobLeaderService:123 - Start job leader service.
2022-04-08 09:48:44 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:116 - User file cache uses directory C:\Users\lixz\AppData\Local\Temp\flink-dist-cache-df384a44-1bcc-44d8-93f5-f733d82fe338
2022-04-08 09:48:44 [main] INFO  DispatcherRestEndpoint:139 - Starting rest endpoint.
2022-04-08 09:48:44 [main] INFO  DispatcherRestEndpoint:126 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2022-04-08 09:48:44 [main] WARN  WebMonitorUtils:82 - Log file environment variable 'log.file' is not set.
2022-04-08 09:48:44 [main] WARN  WebMonitorUtils:88 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
2022-04-08 09:48:46 [main] INFO  DispatcherRestEndpoint:250 - Rest endpoint listening at localhost:64005
2022-04-08 09:48:46 [main] INFO  EmbeddedLeaderService:308 - Proposing leadership to contender http://localhost:64005
2022-04-08 09:48:46 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:994 - http://localhost:64005 was granted leadership with leaderSessionID=945fb54f-2e17-4a63-bc51-e9b0888f0384
2022-04-08 09:48:46 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:256 - Received confirmation of leadership for leader http://localhost:64005 , session=945fb54f-2e17-4a63-bc51-e9b0888f0384
2022-04-08 09:48:46 [main] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
2022-04-08 09:48:46 [main] INFO  EmbeddedLeaderService:308 - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:234 - Starting the resource manager.
2022-04-08 09:48:46 [mini-cluster-io-thread-2] INFO  DefaultDispatcherRunner:107 - DefaultDispatcherRunner was granted leadership with leader id e231392a-fec5-4f42-83bf-4b54ef0ac275. Creating new DispatcherLeaderProcess.
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:308 - Proposing leadership to contender LeaderContender: StandaloneResourceManager
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:1230 - ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token b1e47b76a58c6423b7d3aea54a464be1
2022-04-08 09:48:46 [main] INFO  MiniCluster:413 - Flink Mini Cluster started successfully
2022-04-08 09:48:46 [mini-cluster-io-thread-2] INFO  SessionDispatcherLeaderProcess:97 - Start SessionDispatcherLeaderProcess.
2022-04-08 09:48:46 [mini-cluster-io-thread-5] INFO  SessionDispatcherLeaderProcess:117 - Recover all persisted job graphs.
2022-04-08 09:48:46 [mini-cluster-io-thread-5] INFO  SessionDispatcherLeaderProcess:125 - Successfully recovered 0 persisted job graphs.
2022-04-08 09:48:46 [mini-cluster-io-thread-6] INFO  EmbeddedLeaderService:256 - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=b7d3aea5-4a46-4be1-b1e4-7b76a58c6423
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1293 - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b1e47b76a58c6423b7d3aea54a464be1).
2022-04-08 09:48:46 [mini-cluster-io-thread-5] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
2022-04-08 09:48:46 [mini-cluster-io-thread-5] INFO  EmbeddedLeaderService:256 - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=e231392a-fec5-4f42-83bf-4b54ef0ac275
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:162 - Resolved ResourceManager address, beginning registration
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:982 - Registering TaskManager with ResourceID 0eaf7902-ad14-4fe7-b3a4-2cbeddb259ef (akka://flink/user/rpc/taskmanager_0) at ResourceManager
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:99 - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id fab1a6610c05c580594a21aeab09611f.
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:300 - Received JobGraph submission 5f3683ef89077486687b9de5fd3fa4a0 (collect).
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneDispatcher:362 - Submitting job 5f3683ef89077486687b9de5fd3fa4a0 (collect).
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:308 - Proposing leadership to contender LeaderContender: JobMasterServiceLeadershipRunner
2022-04-08 09:48:46 [jobmanager-future-thread-1] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2022-04-08 09:48:46 [jobmanager-future-thread-1] INFO  JobMaster:289 - Initializing job collect (5f3683ef89077486687b9de5fd3fa4a0).
2022-04-08 09:48:46 [jobmanager-future-thread-1] INFO  JobMaster:98 - Using restart back off time strategy NoRestartBackoffTimeStrategy for collect (5f3683ef89077486687b9de5fd3fa4a0).
2022-04-08 09:48:46 [jobmanager-future-thread-1] INFO  JobMaster:159 - Running initialization on master for job collect (5f3683ef89077486687b9de5fd3fa4a0).
2022-04-08 09:48:46 [jobmanager-future-thread-1] INFO  JobMaster:183 - Successfully ran initialization on master in 0 ms.
2022-04-08 09:48:46 [jobmanager-future-thread-1] INFO  DefaultExecutionTopology:271 - Built 1 pipelined regions in 1 ms
2022-04-08 09:48:46 [jobmanager-future-thread-1] INFO  JobMaster:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@780bc9c2
2022-04-08 09:48:46 [jobmanager-future-thread-1] INFO  JobMaster:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:48:46 [jobmanager-future-thread-1] INFO  CheckpointCoordinator:1532 - No checkpoint found during restore.
2022-04-08 09:48:46 [jobmanager-future-thread-1] INFO  JobMaster:145 - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@7f104c5a for collect (5f3683ef89077486687b9de5fd3fa4a0).
2022-04-08 09:48:46 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:256 - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=823a6c2e-b6b3-4ca8-9467-f4523d08aada
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  JobMaster:867 - Starting execution of job collect (5f3683ef89077486687b9de5fd3fa4a0) under job master id 9467f4523d08aada823a6c2eb6b34ca8.
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  SourceCoordinator:113 - Starting split enumerator for source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]).
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  JobMaster:183 - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1039 - Job collect (5f3683ef89077486687b9de5fd3fa4a0) switched from state CREATED to RUNNING.
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (0159fe90c5729351022c37e07b2e9f7c) switched from CREATED to SCHEDULED.
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (17562783f1c9025023f72c6fd7fd4447) switched from CREATED to SCHEDULED.
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (eb6a9910afcc621609befdab6b99adb5) switched from CREATED to SCHEDULED.
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (02e7128507f9b4d869abac1dc89b4fcf) switched from CREATED to SCHEDULED.
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (c38ed3c52d5f871ed262e9490eea9b49) switched from CREATED to SCHEDULED.
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (f7742696621a79b69cf00c81cbb91a8b) switched from CREATED to SCHEDULED.
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (3a2cb8187cbbf6eb243bf2193735cc0d) switched from CREATED to SCHEDULED.
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (65338693324a86f6060128bbcd7c4de7) switched from CREATED to SCHEDULED.
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (135567748f8e77b5590b111c8112aea8) switched from CREATED to SCHEDULED.
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  JobMaster:1040 - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b1e47b76a58c6423b7d3aea54a464be1)
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  JobMaster:162 - Resolved ResourceManager address, beginning registration
2022-04-08 09:48:46 [flink-akka.actor.default-dispatcher-6] INFO  StandaloneResourceManager:355 - Registering job manager 9467f4523d08aada823a6c2eb6b34ca8@akka://flink/user/rpc/jobmanager_3 for job 5f3683ef89077486687b9de5fd3fa4a0.
2022-04-08 09:48:46 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  ConsumerConfig:347 - ConsumerConfig values: 
	allow.auto.create.topics = false
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [awnx1-cdata-tnode06:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = g1-enumerator-consumer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = g1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:909 - Registered job manager 9467f4523d08aada823a6c2eb6b34ca8@akka://flink/user/rpc/jobmanager_3 for job 5f3683ef89077486687b9de5fd3fa4a0.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  JobMaster:1064 - JobManager successfully registered at ResourceManager, leader id: b1e47b76a58c6423b7d3aea54a464be1.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-4] INFO  DeclarativeSlotManager:263 - Received resource requirements from job 5f3683ef89077486687b9de5fd3fa4a0: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=8}]
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1027 - Receive slot request ab8f6542314108e476eeed5c96f1185b for job 5f3683ef89077486687b9de5fd3fa4a0 from resource manager with leader id b1e47b76a58c6423b7d3aea54a464be1.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1104 - Allocated slot for ab8f6542314108e476eeed5c96f1185b.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  DefaultJobLeaderService:188 - Add job 5f3683ef89077486687b9de5fd3fa4a0 for job leader monitoring.
2022-04-08 09:48:47 [mini-cluster-io-thread-17] INFO  DefaultJobLeaderService:346 - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id 823a6c2e-b6b3-4ca8-9467-f4523d08aada.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1027 - Receive slot request 43ff43e4a875067609c432fd40962d98 for job 5f3683ef89077486687b9de5fd3fa4a0 from resource manager with leader id b1e47b76a58c6423b7d3aea54a464be1.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1104 - Allocated slot for 43ff43e4a875067609c432fd40962d98.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1027 - Receive slot request 60aefe6fd831ab741861d84e796c590f for job 5f3683ef89077486687b9de5fd3fa4a0 from resource manager with leader id b1e47b76a58c6423b7d3aea54a464be1.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-4] INFO  DefaultJobLeaderService:162 - Resolved JobManager address, beginning registration
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1104 - Allocated slot for 60aefe6fd831ab741861d84e796c590f.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1027 - Receive slot request 6e44c8fbbb5fa34bc9e5adeda5ffabf7 for job 5f3683ef89077486687b9de5fd3fa4a0 from resource manager with leader id b1e47b76a58c6423b7d3aea54a464be1.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1104 - Allocated slot for 6e44c8fbbb5fa34bc9e5adeda5ffabf7.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1027 - Receive slot request f8e6ca626b35aec2657b97d1d0f08a77 for job 5f3683ef89077486687b9de5fd3fa4a0 from resource manager with leader id b1e47b76a58c6423b7d3aea54a464be1.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1104 - Allocated slot for f8e6ca626b35aec2657b97d1d0f08a77.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1027 - Receive slot request f61a9ffcd475d67193b040aee085e533 for job 5f3683ef89077486687b9de5fd3fa4a0 from resource manager with leader id b1e47b76a58c6423b7d3aea54a464be1.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1104 - Allocated slot for f61a9ffcd475d67193b040aee085e533.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1027 - Receive slot request 6032d9b40e26d073b6b11f9b1a30f828 for job 5f3683ef89077486687b9de5fd3fa4a0 from resource manager with leader id b1e47b76a58c6423b7d3aea54a464be1.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1104 - Allocated slot for 6032d9b40e26d073b6b11f9b1a30f828.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1027 - Receive slot request 5649b2370f918d5abcd4b3f41a8da2bc for job 5f3683ef89077486687b9de5fd3fa4a0 from resource manager with leader id b1e47b76a58c6423b7d3aea54a464be1.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1104 - Allocated slot for 5649b2370f918d5abcd4b3f41a8da2bc.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  DefaultJobLeaderService:413 - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job 5f3683ef89077486687b9de5fd3fa4a0.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1608 - Establish JobManager connection for job 5f3683ef89077486687b9de5fd3fa4a0.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1459 - Offer reserved slots to the leader of job 5f3683ef89077486687b9de5fd3fa4a0.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (0159fe90c5729351022c37e07b2e9f7c) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (attempt #0) with attempt id 0159fe90c5729351022c37e07b2e9f7c to 0eaf7902-ad14-4fe7-b3a4-2cbeddb259ef @ 127.0.0.1 (dataPort=-1) with allocation id 6e44c8fbbb5fa34bc9e5adeda5ffabf7
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (17562783f1c9025023f72c6fd7fd4447) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (attempt #0) with attempt id 17562783f1c9025023f72c6fd7fd4447 to 0eaf7902-ad14-4fe7-b3a4-2cbeddb259ef @ 127.0.0.1 (dataPort=-1) with allocation id 6032d9b40e26d073b6b11f9b1a30f828
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:388 - Activate slot 6e44c8fbbb5fa34bc9e5adeda5ffabf7.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (eb6a9910afcc621609befdab6b99adb5) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (attempt #0) with attempt id eb6a9910afcc621609befdab6b99adb5 to 0eaf7902-ad14-4fe7-b3a4-2cbeddb259ef @ 127.0.0.1 (dataPort=-1) with allocation id f61a9ffcd475d67193b040aee085e533
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (02e7128507f9b4d869abac1dc89b4fcf) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (attempt #0) with attempt id 02e7128507f9b4d869abac1dc89b4fcf to 0eaf7902-ad14-4fe7-b3a4-2cbeddb259ef @ 127.0.0.1 (dataPort=-1) with allocation id 5649b2370f918d5abcd4b3f41a8da2bc
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (c38ed3c52d5f871ed262e9490eea9b49) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (attempt #0) with attempt id c38ed3c52d5f871ed262e9490eea9b49 to 0eaf7902-ad14-4fe7-b3a4-2cbeddb259ef @ 127.0.0.1 (dataPort=-1) with allocation id 60aefe6fd831ab741861d84e796c590f
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (f7742696621a79b69cf00c81cbb91a8b) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (attempt #0) with attempt id f7742696621a79b69cf00c81cbb91a8b to 0eaf7902-ad14-4fe7-b3a4-2cbeddb259ef @ 127.0.0.1 (dataPort=-1) with allocation id f8e6ca626b35aec2657b97d1d0f08a77
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (3a2cb8187cbbf6eb243bf2193735cc0d) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (attempt #0) with attempt id 3a2cb8187cbbf6eb243bf2193735cc0d to 0eaf7902-ad14-4fe7-b3a4-2cbeddb259ef @ 127.0.0.1 (dataPort=-1) with allocation id ab8f6542314108e476eeed5c96f1185b
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (65338693324a86f6060128bbcd7c4de7) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (attempt #0) with attempt id 65338693324a86f6060128bbcd7c4de7 to 0eaf7902-ad14-4fe7-b3a4-2cbeddb259ef @ 127.0.0.1 (dataPort=-1) with allocation id 43ff43e4a875067609c432fd40962d98
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (135567748f8e77b5590b111c8112aea8) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:571 - Deploying Sink: Collect table sink (1/1) (attempt #0) with attempt id 135567748f8e77b5590b111c8112aea8 to 0eaf7902-ad14-4fe7-b3a4-2cbeddb259ef @ 127.0.0.1 (dataPort=-1) with allocation id 6e44c8fbbb5fa34bc9e5adeda5ffabf7
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (0159fe90c5729351022c37e07b2e9f7c), deploy into slot with allocation id 6e44c8fbbb5fa34bc9e5adeda5ffabf7.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (0159fe90c5729351022c37e07b2e9f7c) switched from CREATED to DEPLOYING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:388 - Activate slot 6032d9b40e26d073b6b11f9b1a30f828.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (17562783f1c9025023f72c6fd7fd4447), deploy into slot with allocation id 6032d9b40e26d073b6b11f9b1a30f828.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:388 - Activate slot f61a9ffcd475d67193b040aee085e533.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (17562783f1c9025023f72c6fd7fd4447) switched from CREATED to DEPLOYING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (0159fe90c5729351022c37e07b2e9f7c) [DEPLOYING].
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (17562783f1c9025023f72c6fd7fd4447) [DEPLOYING].
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (eb6a9910afcc621609befdab6b99adb5), deploy into slot with allocation id f61a9ffcd475d67193b040aee085e533.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:388 - Activate slot 5649b2370f918d5abcd4b3f41a8da2bc.
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  ConsumerConfig:355 - The configuration 'client.id.prefix' was supplied but isn't a known config.
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  ConsumerConfig:355 - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (02e7128507f9b4d869abac1dc89b4fcf), deploy into slot with allocation id 5649b2370f918d5abcd4b3f41a8da2bc.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:388 - Activate slot 60aefe6fd831ab741861d84e796c590f.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (02e7128507f9b4d869abac1dc89b4fcf) switched from CREATED to DEPLOYING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (eb6a9910afcc621609befdab6b99adb5) switched from CREATED to DEPLOYING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (02e7128507f9b4d869abac1dc89b4fcf) [DEPLOYING].
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (eb6a9910afcc621609befdab6b99adb5) [DEPLOYING].
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:117 - Kafka version: 2.4.1
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:118 - Kafka commitId: c57222ae8cd7866b
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:119 - Kafka startTimeMs: 1649382527101
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (c38ed3c52d5f871ed262e9490eea9b49), deploy into slot with allocation id 60aefe6fd831ab741861d84e796c590f.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:388 - Activate slot f8e6ca626b35aec2657b97d1d0f08a77.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (c38ed3c52d5f871ed262e9490eea9b49) switched from CREATED to DEPLOYING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (c38ed3c52d5f871ed262e9490eea9b49) [DEPLOYING].
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (f7742696621a79b69cf00c81cbb91a8b), deploy into slot with allocation id f8e6ca626b35aec2657b97d1d0f08a77.
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AdminClientConfig:347 - AdminClientConfig values: 
	bootstrap.servers = [awnx1-cdata-tnode06:6667]
	client.dns.lookup = default
	client.id = g1-enumerator-admin-client
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:388 - Activate slot ab8f6542314108e476eeed5c96f1185b.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (f7742696621a79b69cf00c81cbb91a8b) switched from CREATED to DEPLOYING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (f7742696621a79b69cf00c81cbb91a8b) [DEPLOYING].
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (3a2cb8187cbbf6eb243bf2193735cc0d), deploy into slot with allocation id ab8f6542314108e476eeed5c96f1185b.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:388 - Activate slot 43ff43e4a875067609c432fd40962d98.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (3a2cb8187cbbf6eb243bf2193735cc0d) switched from CREATED to DEPLOYING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (3a2cb8187cbbf6eb243bf2193735cc0d) [DEPLOYING].
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (65338693324a86f6060128bbcd7c4de7), deploy into slot with allocation id 43ff43e4a875067609c432fd40962d98.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:388 - Activate slot 6e44c8fbbb5fa34bc9e5adeda5ffabf7.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (65338693324a86f6060128bbcd7c4de7) switched from CREATED to DEPLOYING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (65338693324a86f6060128bbcd7c4de7) [DEPLOYING].
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:722 - Received task Sink: Collect table sink (1/1)#0 (135567748f8e77b5590b111c8112aea8), deploy into slot with allocation id 6e44c8fbbb5fa34bc9e5adeda5ffabf7.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@131b8b25
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@545103a7
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:388 - Activate slot ab8f6542314108e476eeed5c96f1185b.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6a28df9c
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:388 - Activate slot 6032d9b40e26d073b6b11f9b1a30f828.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@359671c8
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:388 - Activate slot 5649b2370f918d5abcd4b3f41a8da2bc.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:388 - Activate slot 60aefe6fd831ab741861d84e796c590f.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:388 - Activate slot f61a9ffcd475d67193b040aee085e533.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@9dc4b06
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@1eaa1150
2022-04-08 09:48:47 [Sink: Collect table sink (1/1)#0] INFO  Task:1067 - Sink: Collect table sink (1/1)#0 (135567748f8e77b5590b111c8112aea8) switched from CREATED to DEPLOYING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:388 - Activate slot 6e44c8fbbb5fa34bc9e5adeda5ffabf7.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3f755462
2022-04-08 09:48:47 [Sink: Collect table sink (1/1)#0] INFO  Task:626 - Loading JAR files for task Sink: Collect table sink (1/1)#0 (135567748f8e77b5590b111c8112aea8) [DEPLOYING].
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:388 - Activate slot f8e6ca626b35aec2657b97d1d0f08a77.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:388 - Activate slot 43ff43e4a875067609c432fd40962d98.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@59abcf1b
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:48:47 [Sink: Collect table sink (1/1)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@314f5e15
2022-04-08 09:48:47 [Sink: Collect table sink (1/1)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (eb6a9910afcc621609befdab6b99adb5) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (02e7128507f9b4d869abac1dc89b4fcf) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (3a2cb8187cbbf6eb243bf2193735cc0d) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (65338693324a86f6060128bbcd7c4de7) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (17562783f1c9025023f72c6fd7fd4447) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (c38ed3c52d5f871ed262e9490eea9b49) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (0159fe90c5729351022c37e07b2e9f7c) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (f7742696621a79b69cf00c81cbb91a8b) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [Sink: Collect table sink (1/1)#0] INFO  Task:1067 - Sink: Collect table sink (1/1)#0 (135567748f8e77b5590b111c8112aea8) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (eb6a9910afcc621609befdab6b99adb5) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'key.deserializer' was supplied but isn't a known config.
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'value.deserializer' was supplied but isn't a known config.
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'group.id' was supplied but isn't a known config.
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'client.id.prefix' was supplied but isn't a known config.
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:117 - Kafka version: 2.4.1
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:118 - Kafka commitId: c57222ae8cd7866b
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:119 - Kafka startTimeMs: 1649382527187
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (3a2cb8187cbbf6eb243bf2193735cc0d) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  KafkaSourceEnumerator:157 - Starting the KafkaSourceEnumerator for consumer group g1 without periodic partition discovery.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (02e7128507f9b4d869abac1dc89b4fcf) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (65338693324a86f6060128bbcd7c4de7) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (17562783f1c9025023f72c6fd7fd4447) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (c38ed3c52d5f871ed262e9490eea9b49) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (0159fe90c5729351022c37e07b2e9f7c) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (f7742696621a79b69cf00c81cbb91a8b) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (135567748f8e77b5590b111c8112aea8) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:48:47 [Sink: Collect table sink (1/1)#0] INFO  CollectSinkFunction:205 - Initializing collect sink state with offset = 0, buffered results bytes = 0
2022-04-08 09:48:47 [Sink: Collect table sink (1/1)#0] INFO  CollectSinkFunction:258 - Collect sink server established, address = localhost/127.0.0.1:64014
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-3] INFO  CollectSinkOperatorCoordinator:92 - Received sink socket server address: localhost/127.0.0.1:64014
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 5 @ 
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (f7742696621a79b69cf00c81cbb91a8b) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (17562783f1c9025023f72c6fd7fd4447) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 6 @ 
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (65338693324a86f6060128bbcd7c4de7) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (c38ed3c52d5f871ed262e9490eea9b49) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (0159fe90c5729351022c37e07b2e9f7c) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 0 @ 
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (3a2cb8187cbbf6eb243bf2193735cc0d) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (02e7128507f9b4d869abac1dc89b4fcf) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 4 @ 
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 2 @ 
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 7 @ 
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 1 @ 
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 3 @ 
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (eb6a9910afcc621609befdab6b99adb5) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (f7742696621a79b69cf00c81cbb91a8b) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (17562783f1c9025023f72c6fd7fd4447) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (65338693324a86f6060128bbcd7c4de7) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (c38ed3c52d5f871ed262e9490eea9b49) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (0159fe90c5729351022c37e07b2e9f7c) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (3a2cb8187cbbf6eb243bf2193735cc0d) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [Sink: Collect table sink (1/1)#0] INFO  Task:1067 - Sink: Collect table sink (1/1)#0 (135567748f8e77b5590b111c8112aea8) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (02e7128507f9b4d869abac1dc89b4fcf) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (eb6a9910afcc621609befdab6b99adb5) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (135567748f8e77b5590b111c8112aea8) switched from INITIALIZING to RUNNING.
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])-worker-thread-1] INFO  TopicListSubscriber:68 - The following partitions have been added to the Kafka cluster. [test1-0]
2022-04-08 09:48:47 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  KafkaSourceEnumerator:299 - Assigning splits to readers {1=[[Partition: test1-0, StartingOffset: -1, StoppingOffset: -9223372036854775808]]}
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SourceReaderBase:220 - Adding split(s) to reader: [[Partition: test1-0, StartingOffset: -1, StoppingOffset: -9223372036854775808]]
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  ConsumerConfig:347 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [awnx1-cdata-tnode06:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = g1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = g1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] WARN  ConsumerConfig:355 - The configuration 'client.id.prefix' was supplied but isn't a known config.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] WARN  ConsumerConfig:355 - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  AppInfoParser:117 - Kafka version: 2.4.1
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  AppInfoParser:118 - Kafka commitId: c57222ae8cd7866b
2022-04-08 09:48:47 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  AppInfoParser:119 - Kafka startTimeMs: 1649382527958
2022-04-08 09:48:47 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SplitFetcher:100 - Starting split fetcher 0
2022-04-08 09:48:47 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  KafkaConsumer:1123 - [Consumer clientId=g1-1, groupId=g1] Subscribed to partition(s): test1-0
2022-04-08 09:48:47 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SubscriptionState:564 - [Consumer clientId=g1-1, groupId=g1] Seeking to LATEST offset of partition test1-0
2022-04-08 09:48:48 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Metadata:259 - [Consumer clientId=g1-1, groupId=g1] Cluster ID: 5yVv1a4oRyO2KnAySdX1qw
2022-04-08 09:48:48 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SubscriptionState:381 - [Consumer clientId=g1-1, groupId=g1] Resetting offset for partition test1-0 to offset 113.
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SourceReaderBase:244 - Closing Source Reader.
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SplitFetcher:190 - Shutting down split fetcher 0
2022-04-08 09:48:54 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SplitFetcher:113 - Split fetcher 0 exited.
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] WARN  Task:1074 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (17562783f1c9025023f72c6fd7fd4447) switched from RUNNING to FAILED with failure cause: java.lang.ClassCastException: org.apache.flink.types.RowKind cannot be cast to java.lang.Integer
	at org.apache.flink.api.common.typeutils.base.IntSerializer.copy(IntSerializer.java:30)
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copyPositionBased(RowSerializer.java:163)
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:142)
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:72)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:69)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26)
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:50)
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:28)
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:50)
	at kl.tmp.App2$1.flatMap(App2.java:73)
	at kl.tmp.App2$1.flatMap(App2.java:69)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:71)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26)
	at org.apache.flink.streaming.runtime.tasks.SourceOperatorStreamTask$AsyncDataOutputToOutput.emitRecord(SourceOperatorStreamTask.java:188)
	at org.apache.flink.streaming.api.operators.source.SourceOutputWithWatermarks.collect(SourceOutputWithWatermarks.java:110)
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:36)
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:27)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:128)
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:305)
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:69)
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:66)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:423)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:204)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:684)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.executeInvoke(StreamTask.java:639)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runWithCleanUpOnFail(StreamTask.java:650)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:623)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:779)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:566)
	at java.lang.Thread.run(Thread.java:748)

2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:893 - Freeing task resources for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (17562783f1c9025023f72c6fd7fd4447).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state FAILED to JobManager for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 17562783f1c9025023f72c6fd7fd4447.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1446 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (17562783f1c9025023f72c6fd7fd4447) switched from RUNNING to FAILED on 0eaf7902-ad14-4fe7-b3a4-2cbeddb259ef @ 127.0.0.1 (dataPort=-1).
java.lang.ClassCastException: org.apache.flink.types.RowKind cannot be cast to java.lang.Integer
	at org.apache.flink.api.common.typeutils.base.IntSerializer.copy(IntSerializer.java:30) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copyPositionBased(RowSerializer.java:163) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:142) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:72) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:69) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:50) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:28) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:50) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at kl.tmp.App2$1.flatMap(App2.java:73) ~[classes/:?]
	at kl.tmp.App2$1.flatMap(App2.java:69) ~[classes/:?]
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:71) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.SourceOperatorStreamTask$AsyncDataOutputToOutput.emitRecord(SourceOperatorStreamTask.java:188) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.source.SourceOutputWithWatermarks.collect(SourceOutputWithWatermarks.java:110) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:36) ~[flink-connector-kafka_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:27) ~[flink-connector-kafka_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:128) ~[flink-connector-base-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:305) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:69) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:66) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:423) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:204) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:684) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.executeInvoke(StreamTask.java:639) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runWithCleanUpOnFail(StreamTask.java:650) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:623) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:779) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:566) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-4] INFO  DeclarativeSlotManager:263 - Received resource requirements from job 5f3683ef89077486687b9de5fd3fa4a0: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=7}]
2022-04-08 09:48:54 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:205 - Removing registered reader after failure for subtask 1 of source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  RestartPipelinedRegionFailoverStrategy:115 - Calculating tasks to restart to recover the failed task cbc357ccb763df2852fee8c4fc7d55f2_1.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  RestartPipelinedRegionFailoverStrategy:152 - 9 tasks should be restarted to recover the failed task cbc357ccb763df2852fee8c4fc7d55f2_1. 
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1039 - Job collect (5f3683ef89077486687b9de5fd3fa4a0) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:138) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:82) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:216) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:206) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:197) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:682) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:79) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:435) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_181]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_181]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:77) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) [scala-library-2.11.12.jar:?]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) [scala-library-2.11.12.jar:?]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) [scala-library-2.11.12.jar:?]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) [scala-library-2.11.12.jar:?]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [akka-actor_2.11-2.5.21.jar:2.5.21]
Caused by: java.lang.ClassCastException: org.apache.flink.types.RowKind cannot be cast to java.lang.Integer
	at org.apache.flink.api.common.typeutils.base.IntSerializer.copy(IntSerializer.java:30) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copyPositionBased(RowSerializer.java:163) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:142) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:72) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:69) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:50) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:28) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:50) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at kl.tmp.App2$1.flatMap(App2.java:73) ~[classes/:?]
	at kl.tmp.App2$1.flatMap(App2.java:69) ~[classes/:?]
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:71) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.SourceOperatorStreamTask$AsyncDataOutputToOutput.emitRecord(SourceOperatorStreamTask.java:188) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.source.SourceOutputWithWatermarks.collect(SourceOutputWithWatermarks.java:110) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:36) ~[flink-connector-kafka_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:27) ~[flink-connector-kafka_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:128) ~[flink-connector-base-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:305) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:69) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:66) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:423) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:204) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:684) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.executeInvoke(StreamTask.java:639) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runWithCleanUpOnFail(StreamTask.java:650) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:623) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:779) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:566) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (0159fe90c5729351022c37e07b2e9f7c) switched from RUNNING to CANCELING.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1102 - Attempting to cancel task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (0159fe90c5729351022c37e07b2e9f7c).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (0159fe90c5729351022c37e07b2e9f7c) switched from RUNNING to CANCELING.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1168 - Triggering cancellation of task code Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (0159fe90c5729351022c37e07b2e9f7c).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (eb6a9910afcc621609befdab6b99adb5) switched from RUNNING to CANCELING.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (02e7128507f9b4d869abac1dc89b4fcf) switched from RUNNING to CANCELING.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (c38ed3c52d5f871ed262e9490eea9b49) switched from RUNNING to CANCELING.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (f7742696621a79b69cf00c81cbb91a8b) switched from RUNNING to CANCELING.
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  SourceReaderBase:244 - Closing Source Reader.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (3a2cb8187cbbf6eb243bf2193735cc0d) switched from RUNNING to CANCELING.
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (0159fe90c5729351022c37e07b2e9f7c) switched from CANCELING to CANCELED.
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:893 - Freeing task resources for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (0159fe90c5729351022c37e07b2e9f7c).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1102 - Attempting to cancel task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (eb6a9910afcc621609befdab6b99adb5).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (65338693324a86f6060128bbcd7c4de7) switched from RUNNING to CANCELING.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (eb6a9910afcc621609befdab6b99adb5) switched from RUNNING to CANCELING.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1168 - Triggering cancellation of task code Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (eb6a9910afcc621609befdab6b99adb5).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (135567748f8e77b5590b111c8112aea8) switched from RUNNING to CANCELING.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1102 - Attempting to cancel task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (02e7128507f9b4d869abac1dc89b4fcf).
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  SourceReaderBase:244 - Closing Source Reader.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (02e7128507f9b4d869abac1dc89b4fcf) switched from RUNNING to CANCELING.
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (eb6a9910afcc621609befdab6b99adb5) switched from CANCELING to CANCELED.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1168 - Triggering cancellation of task code Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (02e7128507f9b4d869abac1dc89b4fcf).
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:893 - Freeing task resources for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (eb6a9910afcc621609befdab6b99adb5).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1102 - Attempting to cancel task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (c38ed3c52d5f871ed262e9490eea9b49).
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  SourceReaderBase:244 - Closing Source Reader.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (c38ed3c52d5f871ed262e9490eea9b49) switched from RUNNING to CANCELING.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1168 - Triggering cancellation of task code Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (c38ed3c52d5f871ed262e9490eea9b49).
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (02e7128507f9b4d869abac1dc89b4fcf) switched from CANCELING to CANCELED.
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:893 - Freeing task resources for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (02e7128507f9b4d869abac1dc89b4fcf).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1102 - Attempting to cancel task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (f7742696621a79b69cf00c81cbb91a8b).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (f7742696621a79b69cf00c81cbb91a8b) switched from RUNNING to CANCELING.
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  SourceReaderBase:244 - Closing Source Reader.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1168 - Triggering cancellation of task code Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (f7742696621a79b69cf00c81cbb91a8b).
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (c38ed3c52d5f871ed262e9490eea9b49) switched from CANCELING to CANCELED.
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:893 - Freeing task resources for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (c38ed3c52d5f871ed262e9490eea9b49).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1102 - Attempting to cancel task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (3a2cb8187cbbf6eb243bf2193735cc0d).
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  SourceReaderBase:244 - Closing Source Reader.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (3a2cb8187cbbf6eb243bf2193735cc0d) switched from RUNNING to CANCELING.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1168 - Triggering cancellation of task code Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (3a2cb8187cbbf6eb243bf2193735cc0d).
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (f7742696621a79b69cf00c81cbb91a8b) switched from CANCELING to CANCELED.
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:893 - Freeing task resources for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (f7742696621a79b69cf00c81cbb91a8b).
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  SourceReaderBase:244 - Closing Source Reader.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 0159fe90c5729351022c37e07b2e9f7c.
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (3a2cb8187cbbf6eb243bf2193735cc0d) switched from CANCELING to CANCELED.
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:893 - Freeing task resources for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (3a2cb8187cbbf6eb243bf2193735cc0d).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1102 - Attempting to cancel task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (65338693324a86f6060128bbcd7c4de7).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (0159fe90c5729351022c37e07b2e9f7c) switched from CANCELING to CANCELED.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (65338693324a86f6060128bbcd7c4de7) switched from RUNNING to CANCELING.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1168 - Triggering cancellation of task code Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (65338693324a86f6060128bbcd7c4de7).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1102 - Attempting to cancel task Sink: Collect table sink (1/1)#0 (135567748f8e77b5590b111c8112aea8).
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  SourceReaderBase:244 - Closing Source Reader.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1067 - Sink: Collect table sink (1/1)#0 (135567748f8e77b5590b111c8112aea8) switched from RUNNING to CANCELING.
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (65338693324a86f6060128bbcd7c4de7) switched from CANCELING to CANCELED.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  Task:1168 - Triggering cancellation of task code Sink: Collect table sink (1/1)#0 (135567748f8e77b5590b111c8112aea8).
2022-04-08 09:48:54 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:893 - Freeing task resources for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (65338693324a86f6060128bbcd7c4de7).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 eb6a9910afcc621609befdab6b99adb5.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 02e7128507f9b4d869abac1dc89b4fcf.
2022-04-08 09:48:54 [Sink: Collect table sink (1/1)#0] INFO  Task:1067 - Sink: Collect table sink (1/1)#0 (135567748f8e77b5590b111c8112aea8) switched from CANCELING to CANCELED.
2022-04-08 09:48:54 [Sink: Collect table sink (1/1)#0] INFO  Task:893 - Freeing task resources for Sink: Collect table sink (1/1)#0 (135567748f8e77b5590b111c8112aea8).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (eb6a9910afcc621609befdab6b99adb5) switched from CANCELING to CANCELED.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 c38ed3c52d5f871ed262e9490eea9b49.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-4] INFO  DeclarativeSlotManager:263 - Received resource requirements from job 5f3683ef89077486687b9de5fd3fa4a0: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=6}]
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 f7742696621a79b69cf00c81cbb91a8b.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (02e7128507f9b4d869abac1dc89b4fcf) switched from CANCELING to CANCELED.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 3a2cb8187cbbf6eb243bf2193735cc0d.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 65338693324a86f6060128bbcd7c4de7.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (c38ed3c52d5f871ed262e9490eea9b49) switched from CANCELING to CANCELED.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-8] INFO  DeclarativeSlotManager:263 - Received resource requirements from job 5f3683ef89077486687b9de5fd3fa4a0: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=5}]
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  TaskExecutor:1877 - Un-registering task and sending final execution state CANCELED to JobManager for task Sink: Collect table sink (1/1)#0 135567748f8e77b5590b111c8112aea8.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-8] INFO  DeclarativeSlotManager:263 - Received resource requirements from job 5f3683ef89077486687b9de5fd3fa4a0: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=4}]
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (f7742696621a79b69cf00c81cbb91a8b) switched from CANCELING to CANCELED.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-4] INFO  DeclarativeSlotManager:263 - Received resource requirements from job 5f3683ef89077486687b9de5fd3fa4a0: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=3}]
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (3a2cb8187cbbf6eb243bf2193735cc0d) switched from CANCELING to CANCELED.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  DeclarativeSlotManager:263 - Received resource requirements from job 5f3683ef89077486687b9de5fd3fa4a0: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=2}]
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (65338693324a86f6060128bbcd7c4de7) switched from CANCELING to CANCELED.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-8] INFO  DeclarativeSlotManager:263 - Received resource requirements from job 5f3683ef89077486687b9de5fd3fa4a0: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (135567748f8e77b5590b111c8112aea8) switched from CANCELING to CANCELED.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1039 - Job collect (5f3683ef89077486687b9de5fd3fa4a0) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:138) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:82) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:216) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:206) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:197) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:682) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:79) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:435) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_181]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_181]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:77) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) [scala-library-2.11.12.jar:?]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) [scala-library-2.11.12.jar:?]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) [scala-library-2.11.12.jar:?]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) [scala-library-2.11.12.jar:?]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [akka-actor_2.11-2.5.21.jar:2.5.21]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [akka-actor_2.11-2.5.21.jar:2.5.21]
Caused by: java.lang.ClassCastException: org.apache.flink.types.RowKind cannot be cast to java.lang.Integer
	at org.apache.flink.api.common.typeutils.base.IntSerializer.copy(IntSerializer.java:30) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copyPositionBased(RowSerializer.java:163) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:142) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:72) ~[flink-core-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:69) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:50) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:28) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:50) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at kl.tmp.App2$1.flatMap(App2.java:73) ~[classes/:?]
	at kl.tmp.App2$1.flatMap(App2.java:69) ~[classes/:?]
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:71) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.SourceOperatorStreamTask$AsyncDataOutputToOutput.emitRecord(SourceOperatorStreamTask.java:188) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.source.SourceOutputWithWatermarks.collect(SourceOutputWithWatermarks.java:110) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:36) ~[flink-connector-kafka_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:27) ~[flink-connector-kafka_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:128) ~[flink-connector-base-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:305) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:69) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:66) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:423) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:204) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:684) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.executeInvoke(StreamTask.java:639) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runWithCleanUpOnFail(StreamTask.java:650) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:623) ~[flink-streaming-java_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:779) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:566) ~[flink-runtime_2.11-1.13.6.jar:1.13.6]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  CheckpointCoordinator:406 - Stopping checkpoint coordinator for job 5f3683ef89077486687b9de5fd3fa4a0.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-8] INFO  DeclarativeSlotManager:261 - Clearing resource requirements of job 5f3683ef89077486687b9de5fd3fa4a0
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] WARN  TaskManagerLocation:240 - No hostname could be resolved for the IP address 127.0.0.1, using IP address as host name. Local input split assignment (such as for HDFS files) may be impacted.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  StandaloneCompletedCheckpointStore:96 - Shutting down
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-8] INFO  MiniCluster:530 - Shutting down Flink Mini Cluster
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  StandaloneDispatcher:839 - Job 5f3683ef89077486687b9de5fd3fa4a0 reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:138)
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:82)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:216)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:206)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:197)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:682)
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:79)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:435)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212)
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:77)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)
	at akka.actor.ActorCell.invoke(ActorCell.scala:561)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.ClassCastException: org.apache.flink.types.RowKind cannot be cast to java.lang.Integer
	at org.apache.flink.api.common.typeutils.base.IntSerializer.copy(IntSerializer.java:30)
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copyPositionBased(RowSerializer.java:163)
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:142)
	at org.apache.flink.api.java.typeutils.runtime.RowSerializer.copy(RowSerializer.java:72)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:69)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26)
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:50)
	at org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:28)
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:50)
	at kl.tmp.App2$1.flatMap(App2.java:73)
	at kl.tmp.App2$1.flatMap(App2.java:69)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.pushToOperator(CopyingChainingOutput.java:71)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:46)
	at org.apache.flink.streaming.runtime.tasks.CopyingChainingOutput.collect(CopyingChainingOutput.java:26)
	at org.apache.flink.streaming.runtime.tasks.SourceOperatorStreamTask$AsyncDataOutputToOutput.emitRecord(SourceOperatorStreamTask.java:188)
	at org.apache.flink.streaming.api.operators.source.SourceOutputWithWatermarks.collect(SourceOutputWithWatermarks.java:110)
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:36)
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:27)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:128)
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:305)
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:69)
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:66)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:423)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:204)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:684)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.executeInvoke(StreamTask.java:639)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runWithCleanUpOnFail(StreamTask.java:650)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:623)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:779)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:566)
	at java.lang.Thread.run(Thread.java:748)
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:434 - Stopping TaskExecutor akka://flink/user/rpc/taskmanager_0.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-8] INFO  DispatcherRestEndpoint:309 - Shutting down rest endpoint.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1386 - Close ResourceManager connection 5dbe7b9da48149d2a647972b5a89527d.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:1083 - Closing TaskExecutor connection 0eaf7902-ad14-4fe7-b3a4-2cbeddb259ef because: The TaskExecutor is shutting down.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:1652 - Close JobManager connection for job 5f3683ef89077486687b9de5fd3fa4a0.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  JobMaster:395 - Stopping the JobMaster for job collect(5f3683ef89077486687b9de5fd3fa4a0).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:439 - Free slot TaskSlot(index:0, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: ab8f6542314108e476eeed5c96f1185b, jobId: 5f3683ef89077486687b9de5fd3fa4a0).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:439 - Free slot TaskSlot(index:6, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 6032d9b40e26d073b6b11f9b1a30f828, jobId: 5f3683ef89077486687b9de5fd3fa4a0).
2022-04-08 09:48:54 [Thread-8] INFO  SourceCoordinator:146 - Closing SourceCoordinator for source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:439 - Free slot TaskSlot(index:7, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 5649b2370f918d5abcd4b3f41a8da2bc, jobId: 5f3683ef89077486687b9de5fd3fa4a0).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:439 - Free slot TaskSlot(index:2, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 60aefe6fd831ab741861d84e796c590f, jobId: 5f3683ef89077486687b9de5fd3fa4a0).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:439 - Free slot TaskSlot(index:5, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: f61a9ffcd475d67193b040aee085e533, jobId: 5f3683ef89077486687b9de5fd3fa4a0).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:439 - Free slot TaskSlot(index:3, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 6e44c8fbbb5fa34bc9e5adeda5ffabf7, jobId: 5f3683ef89077486687b9de5fd3fa4a0).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:439 - Free slot TaskSlot(index:4, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: f8e6ca626b35aec2657b97d1d0f08a77, jobId: 5f3683ef89077486687b9de5fd3fa4a0).
2022-04-08 09:48:54 [Thread-8] INFO  SourceCoordinator:160 - Source coordinator for source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) closed.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  DefaultDeclarativeSlotPool:474 - Releasing slot [ab8f6542314108e476eeed5c96f1185b].
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  TaskSlotTableImpl:439 - Free slot TaskSlot(index:1, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=128.000gb (137438953472 bytes), taskOffHeapMemory=128.000gb (137438953472 bytes), managedMemory=16.000mb (16777216 bytes), networkMemory=8.000mb (8388608 bytes)}, allocationId: 43ff43e4a875067609c432fd40962d98, jobId: 5f3683ef89077486687b9de5fd3fa4a0).
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  DefaultDeclarativeSlotPool:474 - Releasing slot [6032d9b40e26d073b6b11f9b1a30f828].
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  DefaultDeclarativeSlotPool:474 - Releasing slot [5649b2370f918d5abcd4b3f41a8da2bc].
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  DefaultDeclarativeSlotPool:474 - Releasing slot [60aefe6fd831ab741861d84e796c590f].
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  DefaultDeclarativeSlotPool:474 - Releasing slot [f61a9ffcd475d67193b040aee085e533].
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  DefaultDeclarativeSlotPool:474 - Releasing slot [6e44c8fbbb5fa34bc9e5adeda5ffabf7].
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  DefaultDeclarativeSlotPool:474 - Releasing slot [f8e6ca626b35aec2657b97d1d0f08a77].
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  DefaultDeclarativeSlotPool:474 - Releasing slot [43ff43e4a875067609c432fd40962d98].
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  JobMaster:1124 - Close ResourceManager connection 5dbe7b9da48149d2a647972b5a89527d: Stopping JobMaster for job collect(5f3683ef89077486687b9de5fd3fa4a0)..
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:1047 - Disconnect job manager 9467f4523d08aada823a6c2eb6b34ca8@akka://flink/user/rpc/jobmanager_3 for job 5f3683ef89077486687b9de5fd3fa4a0 from the resource manager.
2022-04-08 09:48:54 [ForkJoinPool.commonPool-worker-5] INFO  DispatcherRestEndpoint:970 - Removing cache directory C:\Users\lixz\AppData\Local\Temp\flink-web-ui
2022-04-08 09:48:54 [ForkJoinPool.commonPool-worker-5] INFO  DispatcherRestEndpoint:317 - Shut down complete.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-8] INFO  StandaloneResourceManager:629 - Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-8] INFO  DispatcherResourceManagerComponent:162 - Closing components.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-8] INFO  SessionDispatcherLeaderProcess:134 - Stopping SessionDispatcherLeaderProcess.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  StandaloneDispatcher:265 - Stopping dispatcher akka://flink/user/rpc/dispatcher_2.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-7] INFO  StandaloneDispatcher:793 - Stopping all currently running jobs of dispatcher akka://flink/user/rpc/dispatcher_2.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-4] INFO  DeclarativeSlotManager:240 - Closing the slot manager.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-4] INFO  DeclarativeSlotManager:212 - Suspending the slot manager.
2022-04-08 09:48:54 [mini-cluster-io-thread-22] INFO  TaskExecutor:2181 - JobManager for job 5f3683ef89077486687b9de5fd3fa4a0 with leader id 9467f4523d08aada823a6c2eb6b34ca8 lost leadership.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  DefaultJobLeaderService:136 - Stop job leader service.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutorLocalStateStoresManager:231 - Shutting down TaskExecutorLocalStateStoresManager.
2022-04-08 09:48:54 [mini-cluster-io-thread-23] INFO  StandaloneDispatcher:277 - Stopped dispatcher akka://flink/user/rpc/dispatcher_2.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  FileChannelManagerImpl:149 - FileChannelManager removed spill file directory C:\Users\lixz\AppData\Local\Temp\flink-io-edb3a558-e3f3-4b12-96ab-064fd3326d45
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  NettyShuffleEnvironment:347 - Shutting down the network environment and its components.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  FileChannelManagerImpl:149 - FileChannelManager removed spill file directory C:\Users\lixz\AppData\Local\Temp\flink-netty-shuffle-23516dab-f56c-481c-9948-e4f226d61b08
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  KvStateService:122 - Shutting down the kvState service and its components.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  DefaultJobLeaderService:136 - Stop job leader service.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  FileCache:160 - removed file cache directory C:\Users\lixz\AppData\Local\Temp\flink-dist-cache-df384a44-1bcc-44d8-93f5-f733d82fe338
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:479 - Stopped TaskExecutor akka://flink/user/rpc/taskmanager_0.
2022-04-08 09:48:54 [AkkaRpcService-Supervisor-Termination-Future-Executor-thread-1] INFO  AkkaRpcService:403 - Stopping Akka RPC service.
2022-04-08 09:48:54 [flink-metrics-2] INFO  AkkaRpcService:403 - Stopping Akka RPC service.
2022-04-08 09:48:54 [flink-metrics-2] INFO  AkkaRpcService:427 - Stopped Akka RPC service.
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-8] INFO  PermanentBlobCache:240 - Shutting down BLOB cache
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-8] INFO  TransientBlobCache:240 - Shutting down BLOB cache
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-8] INFO  BlobServer:345 - Stopped BLOB server at 0.0.0.0:63943
2022-04-08 09:48:54 [flink-akka.actor.default-dispatcher-8] INFO  AkkaRpcService:427 - Stopped Akka RPC service.
2022-04-08 09:50:00 [main] INFO  TypeExtractor:1991 - class java.util.LinkedHashMap does not contain a getter for field accessOrder
2022-04-08 09:50:00 [main] INFO  TypeExtractor:1994 - class java.util.LinkedHashMap does not contain a setter for field accessOrder
2022-04-08 09:50:00 [main] INFO  TypeExtractor:2037 - Class class java.util.LinkedHashMap cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2022-04-08 09:50:00 [main] INFO  TypeExtractor:2093 - class org.apache.flink.types.Row is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2022-04-08 09:50:02 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
2022-04-08 09:50:02 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
2022-04-08 09:50:02 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
2022-04-08 09:50:02 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
2022-04-08 09:50:02 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
2022-04-08 09:50:02 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
2022-04-08 09:50:02 [main] INFO  MiniCluster:269 - Starting Flink Mini Cluster
2022-04-08 09:50:02 [main] INFO  MiniCluster:279 - Starting Metrics Registry
2022-04-08 09:50:02 [main] INFO  MetricRegistryImpl:126 - No metrics reporter configured, no metrics will be exposed/reported.
2022-04-08 09:50:02 [main] INFO  MiniCluster:283 - Starting RPC Service(s)
2022-04-08 09:50:02 [main] INFO  AkkaRpcServiceUtils:265 - Trying to start local actor system
2022-04-08 09:50:02 [flink-akka.actor.default-dispatcher-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2022-04-08 09:50:03 [main] INFO  AkkaRpcServiceUtils:298 - Actor system started at akka://flink
2022-04-08 09:50:03 [main] INFO  AkkaRpcServiceUtils:265 - Trying to start local actor system
2022-04-08 09:50:03 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2022-04-08 09:50:04 [main] INFO  AkkaRpcServiceUtils:298 - Actor system started at akka://flink-metrics
2022-04-08 09:50:04 [main] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2022-04-08 09:50:04 [main] INFO  MiniCluster:487 - Starting high-availability services
2022-04-08 09:50:05 [main] INFO  BlobServer:138 - Created BLOB server storage directory C:\Users\lixz\AppData\Local\Temp\blobStore-f69ae7e2-7ea8-46d1-85ac-d18ef4e5e703
2022-04-08 09:50:05 [main] INFO  BlobServer:213 - Started BLOB server at 0.0.0.0:64176 - max concurrent requests: 50 - max backlog: 1000
2022-04-08 09:50:05 [main] INFO  PermanentBlobCache:90 - Created BLOB cache storage directory C:\Users\lixz\AppData\Local\Temp\blobStore-bdcfa03f-8702-4f13-bb3e-10c8888224a9
2022-04-08 09:50:05 [main] INFO  TransientBlobCache:90 - Created BLOB cache storage directory C:\Users\lixz\AppData\Local\Temp\blobStore-dc48bbf1-ef28-4a47-b9e6-481b41cc0d9f
2022-04-08 09:50:05 [main] INFO  MiniCluster:606 - Starting 1 TaskManger(s)
2022-04-08 09:50:05 [main] INFO  TaskManagerRunner:474 - Starting TaskManager with ResourceID: 1b44f806-956d-499e-8b17-8b5a01e922b1
2022-04-08 09:50:05 [main] INFO  TaskManagerServices:441 - Temporary file directory 'C:\Users\lixz\AppData\Local\Temp': total 119 GB, usable 10 GB (8.40% usable)
2022-04-08 09:50:05 [main] INFO  FileChannelManagerImpl:98 - FileChannelManager uses directory C:\Users\lixz\AppData\Local\Temp\flink-io-d90d5cd7-b3cb-43c0-9f86-1d7a16b1db4b for spill files.
2022-04-08 09:50:05 [main] INFO  FileChannelManagerImpl:98 - FileChannelManager uses directory C:\Users\lixz\AppData\Local\Temp\flink-netty-shuffle-e3d6bc94-95d9-49fb-9658-424f68609568 for spill files.
2022-04-08 09:50:05 [main] INFO  NetworkBufferPool:145 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2022-04-08 09:50:05 [main] INFO  NettyShuffleEnvironment:328 - Starting the network environment and its components.
2022-04-08 09:50:05 [main] INFO  KvStateService:92 - Starting the kvState service and its components.
2022-04-08 09:50:05 [main] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2022-04-08 09:50:05 [flink-akka.actor.default-dispatcher-2] INFO  DefaultJobLeaderService:123 - Start job leader service.
2022-04-08 09:50:05 [flink-akka.actor.default-dispatcher-2] INFO  FileCache:116 - User file cache uses directory C:\Users\lixz\AppData\Local\Temp\flink-dist-cache-9208008c-39d5-475b-b7d8-d48d077e96da
2022-04-08 09:50:05 [main] INFO  DispatcherRestEndpoint:139 - Starting rest endpoint.
2022-04-08 09:50:05 [main] INFO  DispatcherRestEndpoint:126 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2022-04-08 09:50:05 [main] WARN  WebMonitorUtils:82 - Log file environment variable 'log.file' is not set.
2022-04-08 09:50:05 [main] WARN  WebMonitorUtils:88 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
2022-04-08 09:50:08 [main] INFO  DispatcherRestEndpoint:250 - Rest endpoint listening at localhost:64216
2022-04-08 09:50:08 [main] INFO  EmbeddedLeaderService:308 - Proposing leadership to contender http://localhost:64216
2022-04-08 09:50:08 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:994 - http://localhost:64216 was granted leadership with leaderSessionID=0e0eaee4-f0df-4d3a-87a9-82d8959861e8
2022-04-08 09:50:08 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:256 - Received confirmation of leadership for leader http://localhost:64216 , session=0e0eaee4-f0df-4d3a-87a9-82d8959861e8
2022-04-08 09:50:08 [main] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
2022-04-08 09:50:08 [main] INFO  EmbeddedLeaderService:308 - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:234 - Starting the resource manager.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  EmbeddedLeaderService:308 - Proposing leadership to contender LeaderContender: StandaloneResourceManager
2022-04-08 09:50:08 [mini-cluster-io-thread-2] INFO  DefaultDispatcherRunner:107 - DefaultDispatcherRunner was granted leadership with leader id 89f16083-6042-4cd7-9e39-6bd56b091fb4. Creating new DispatcherLeaderProcess.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  StandaloneResourceManager:1230 - ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token 8a72ddfe524bb306385bef60cf95475a
2022-04-08 09:50:08 [main] INFO  MiniCluster:413 - Flink Mini Cluster started successfully
2022-04-08 09:50:08 [mini-cluster-io-thread-2] INFO  SessionDispatcherLeaderProcess:97 - Start SessionDispatcherLeaderProcess.
2022-04-08 09:50:08 [mini-cluster-io-thread-5] INFO  SessionDispatcherLeaderProcess:117 - Recover all persisted job graphs.
2022-04-08 09:50:08 [mini-cluster-io-thread-5] INFO  SessionDispatcherLeaderProcess:125 - Successfully recovered 0 persisted job graphs.
2022-04-08 09:50:08 [mini-cluster-io-thread-6] INFO  EmbeddedLeaderService:256 - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=385bef60-cf95-475a-8a72-ddfe524bb306
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:1293 - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(8a72ddfe524bb306385bef60cf95475a).
2022-04-08 09:50:08 [mini-cluster-io-thread-5] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
2022-04-08 09:50:08 [mini-cluster-io-thread-5] INFO  EmbeddedLeaderService:256 - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=89f16083-6042-4cd7-9e39-6bd56b091fb4
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:162 - Resolved ResourceManager address, beginning registration
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:982 - Registering TaskManager with ResourceID 1b44f806-956d-499e-8b17-8b5a01e922b1 (akka://flink/user/rpc/taskmanager_0) at ResourceManager
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  TaskExecutor:99 - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id da3b2e0a6cb8166c7d94617dfa46e680.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:300 - Received JobGraph submission ac0b780e5f35fb14f4f6b247970d3d35 (collect).
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:362 - Submitting job ac0b780e5f35fb14f4f6b247970d3d35 (collect).
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:308 - Proposing leadership to contender LeaderContender: JobMasterServiceLeadershipRunner
2022-04-08 09:50:08 [jobmanager-future-thread-1] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2022-04-08 09:50:08 [jobmanager-future-thread-1] INFO  JobMaster:289 - Initializing job collect (ac0b780e5f35fb14f4f6b247970d3d35).
2022-04-08 09:50:08 [jobmanager-future-thread-1] INFO  JobMaster:98 - Using restart back off time strategy NoRestartBackoffTimeStrategy for collect (ac0b780e5f35fb14f4f6b247970d3d35).
2022-04-08 09:50:08 [jobmanager-future-thread-1] INFO  JobMaster:159 - Running initialization on master for job collect (ac0b780e5f35fb14f4f6b247970d3d35).
2022-04-08 09:50:08 [jobmanager-future-thread-1] INFO  JobMaster:183 - Successfully ran initialization on master in 0 ms.
2022-04-08 09:50:08 [jobmanager-future-thread-1] INFO  DefaultExecutionTopology:271 - Built 1 pipelined regions in 1 ms
2022-04-08 09:50:08 [jobmanager-future-thread-1] INFO  JobMaster:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3722ca3e
2022-04-08 09:50:08 [jobmanager-future-thread-1] INFO  JobMaster:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:08 [jobmanager-future-thread-1] INFO  CheckpointCoordinator:1532 - No checkpoint found during restore.
2022-04-08 09:50:08 [jobmanager-future-thread-1] INFO  JobMaster:145 - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@3c4fa4ee for collect (ac0b780e5f35fb14f4f6b247970d3d35).
2022-04-08 09:50:08 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:256 - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=dc3974da-8992-42b1-8eb3-603023950c38
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:867 - Starting execution of job collect (ac0b780e5f35fb14f4f6b247970d3d35) under job master id 8eb3603023950c38dc3974da899242b1.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  SourceCoordinator:113 - Starting split enumerator for source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]).
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:183 - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1039 - Job collect (ac0b780e5f35fb14f4f6b247970d3d35) switched from state CREATED to RUNNING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (6de00c4fa80145ead101f7df10442201) switched from CREATED to SCHEDULED.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (950788f1f30d625eed1c6366a7c08e55) switched from CREATED to SCHEDULED.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (6de74397c46488ed566a7525110163eb) switched from CREATED to SCHEDULED.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (4e942d70fa065ea8c33886f95c9f8aa8) switched from CREATED to SCHEDULED.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (7b0742ffe3b0734d0fe4b927167bdb2c) switched from CREATED to SCHEDULED.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (a31c08da890178b9769fc6c6c5db656d) switched from CREATED to SCHEDULED.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (3e7390afd753fd9bcf3c3c5edae90c83) switched from CREATED to SCHEDULED.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (9e144a879b7d9f6a5167f4cde1948bc0) switched from CREATED to SCHEDULED.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (fa5f264f0cfae7984306006ad0b43903) switched from CREATED to SCHEDULED.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  JobMaster:1040 - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(8a72ddfe524bb306385bef60cf95475a)
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  JobMaster:162 - Resolved ResourceManager address, beginning registration
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:355 - Registering job manager 8eb3603023950c38dc3974da899242b1@akka://flink/user/rpc/jobmanager_3 for job ac0b780e5f35fb14f4f6b247970d3d35.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  ConsumerConfig:347 - ConsumerConfig values: 
	allow.auto.create.topics = false
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [awnx1-cdata-tnode06:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = g1-enumerator-consumer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = g1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:909 - Registered job manager 8eb3603023950c38dc3974da899242b1@akka://flink/user/rpc/jobmanager_3 for job ac0b780e5f35fb14f4f6b247970d3d35.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:1064 - JobManager successfully registered at ResourceManager, leader id: 8a72ddfe524bb306385bef60cf95475a.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-2] INFO  DeclarativeSlotManager:263 - Received resource requirements from job ac0b780e5f35fb14f4f6b247970d3d35: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=8}]
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1027 - Receive slot request 10020bd55fd6dadb00aac5166da0c55d for job ac0b780e5f35fb14f4f6b247970d3d35 from resource manager with leader id 8a72ddfe524bb306385bef60cf95475a.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1104 - Allocated slot for 10020bd55fd6dadb00aac5166da0c55d.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  DefaultJobLeaderService:188 - Add job ac0b780e5f35fb14f4f6b247970d3d35 for job leader monitoring.
2022-04-08 09:50:08 [mini-cluster-io-thread-17] INFO  DefaultJobLeaderService:346 - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id dc3974da-8992-42b1-8eb3-603023950c38.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1027 - Receive slot request 4f65c27498b35a4d694ad39f2282ea2c for job ac0b780e5f35fb14f4f6b247970d3d35 from resource manager with leader id 8a72ddfe524bb306385bef60cf95475a.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1104 - Allocated slot for 4f65c27498b35a4d694ad39f2282ea2c.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  DefaultJobLeaderService:162 - Resolved JobManager address, beginning registration
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1027 - Receive slot request f20ad3199712a0b550621ad098297c62 for job ac0b780e5f35fb14f4f6b247970d3d35 from resource manager with leader id 8a72ddfe524bb306385bef60cf95475a.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1104 - Allocated slot for f20ad3199712a0b550621ad098297c62.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1027 - Receive slot request d0f39bf079e2c8cd65d070496ac43b02 for job ac0b780e5f35fb14f4f6b247970d3d35 from resource manager with leader id 8a72ddfe524bb306385bef60cf95475a.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1104 - Allocated slot for d0f39bf079e2c8cd65d070496ac43b02.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1027 - Receive slot request a9dc4b9b6ad6ba0325e8dd731d71db11 for job ac0b780e5f35fb14f4f6b247970d3d35 from resource manager with leader id 8a72ddfe524bb306385bef60cf95475a.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1104 - Allocated slot for a9dc4b9b6ad6ba0325e8dd731d71db11.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1027 - Receive slot request d99f887b9438786dc4c2e273b0225ab0 for job ac0b780e5f35fb14f4f6b247970d3d35 from resource manager with leader id 8a72ddfe524bb306385bef60cf95475a.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1104 - Allocated slot for d99f887b9438786dc4c2e273b0225ab0.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1027 - Receive slot request 72a7c831a97bfff971a2834b23e2f16d for job ac0b780e5f35fb14f4f6b247970d3d35 from resource manager with leader id 8a72ddfe524bb306385bef60cf95475a.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1104 - Allocated slot for 72a7c831a97bfff971a2834b23e2f16d.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1027 - Receive slot request 30a01b6251481ee86bf18331cc8831d5 for job ac0b780e5f35fb14f4f6b247970d3d35 from resource manager with leader id 8a72ddfe524bb306385bef60cf95475a.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1104 - Allocated slot for 30a01b6251481ee86bf18331cc8831d5.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  DefaultJobLeaderService:413 - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job ac0b780e5f35fb14f4f6b247970d3d35.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1608 - Establish JobManager connection for job ac0b780e5f35fb14f4f6b247970d3d35.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:1459 - Offer reserved slots to the leader of job ac0b780e5f35fb14f4f6b247970d3d35.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (6de00c4fa80145ead101f7df10442201) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (attempt #0) with attempt id 6de00c4fa80145ead101f7df10442201 to 1b44f806-956d-499e-8b17-8b5a01e922b1 @ 127.0.0.1 (dataPort=-1) with allocation id f20ad3199712a0b550621ad098297c62
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (950788f1f30d625eed1c6366a7c08e55) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTableImpl:388 - Activate slot f20ad3199712a0b550621ad098297c62.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (attempt #0) with attempt id 950788f1f30d625eed1c6366a7c08e55 to 1b44f806-956d-499e-8b17-8b5a01e922b1 @ 127.0.0.1 (dataPort=-1) with allocation id 10020bd55fd6dadb00aac5166da0c55d
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (6de74397c46488ed566a7525110163eb) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (attempt #0) with attempt id 6de74397c46488ed566a7525110163eb to 1b44f806-956d-499e-8b17-8b5a01e922b1 @ 127.0.0.1 (dataPort=-1) with allocation id 72a7c831a97bfff971a2834b23e2f16d
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (4e942d70fa065ea8c33886f95c9f8aa8) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (attempt #0) with attempt id 4e942d70fa065ea8c33886f95c9f8aa8 to 1b44f806-956d-499e-8b17-8b5a01e922b1 @ 127.0.0.1 (dataPort=-1) with allocation id 30a01b6251481ee86bf18331cc8831d5
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (7b0742ffe3b0734d0fe4b927167bdb2c) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (attempt #0) with attempt id 7b0742ffe3b0734d0fe4b927167bdb2c to 1b44f806-956d-499e-8b17-8b5a01e922b1 @ 127.0.0.1 (dataPort=-1) with allocation id 4f65c27498b35a4d694ad39f2282ea2c
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (a31c08da890178b9769fc6c6c5db656d) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (attempt #0) with attempt id a31c08da890178b9769fc6c6c5db656d to 1b44f806-956d-499e-8b17-8b5a01e922b1 @ 127.0.0.1 (dataPort=-1) with allocation id a9dc4b9b6ad6ba0325e8dd731d71db11
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (3e7390afd753fd9bcf3c3c5edae90c83) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (attempt #0) with attempt id 3e7390afd753fd9bcf3c3c5edae90c83 to 1b44f806-956d-499e-8b17-8b5a01e922b1 @ 127.0.0.1 (dataPort=-1) with allocation id d99f887b9438786dc4c2e273b0225ab0
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (9e144a879b7d9f6a5167f4cde1948bc0) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (attempt #0) with attempt id 9e144a879b7d9f6a5167f4cde1948bc0 to 1b44f806-956d-499e-8b17-8b5a01e922b1 @ 127.0.0.1 (dataPort=-1) with allocation id d0f39bf079e2c8cd65d070496ac43b02
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (fa5f264f0cfae7984306006ad0b43903) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-6] INFO  ExecutionGraph:571 - Deploying Sink: Collect table sink (1/1) (attempt #0) with attempt id fa5f264f0cfae7984306006ad0b43903 to 1b44f806-956d-499e-8b17-8b5a01e922b1 @ 127.0.0.1 (dataPort=-1) with allocation id f20ad3199712a0b550621ad098297c62
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (6de00c4fa80145ead101f7df10442201), deploy into slot with allocation id f20ad3199712a0b550621ad098297c62.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (6de00c4fa80145ead101f7df10442201) switched from CREATED to DEPLOYING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTableImpl:388 - Activate slot 10020bd55fd6dadb00aac5166da0c55d.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (950788f1f30d625eed1c6366a7c08e55), deploy into slot with allocation id 10020bd55fd6dadb00aac5166da0c55d.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTableImpl:388 - Activate slot 72a7c831a97bfff971a2834b23e2f16d.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (6de00c4fa80145ead101f7df10442201) [DEPLOYING].
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (950788f1f30d625eed1c6366a7c08e55) switched from CREATED to DEPLOYING.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (950788f1f30d625eed1c6366a7c08e55) [DEPLOYING].
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (6de74397c46488ed566a7525110163eb), deploy into slot with allocation id 72a7c831a97bfff971a2834b23e2f16d.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTableImpl:388 - Activate slot 30a01b6251481ee86bf18331cc8831d5.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (6de74397c46488ed566a7525110163eb) switched from CREATED to DEPLOYING.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (6de74397c46488ed566a7525110163eb) [DEPLOYING].
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (4e942d70fa065ea8c33886f95c9f8aa8), deploy into slot with allocation id 30a01b6251481ee86bf18331cc8831d5.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTableImpl:388 - Activate slot 4f65c27498b35a4d694ad39f2282ea2c.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (4e942d70fa065ea8c33886f95c9f8aa8) switched from CREATED to DEPLOYING.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (4e942d70fa065ea8c33886f95c9f8aa8) [DEPLOYING].
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (7b0742ffe3b0734d0fe4b927167bdb2c), deploy into slot with allocation id 4f65c27498b35a4d694ad39f2282ea2c.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTableImpl:388 - Activate slot a9dc4b9b6ad6ba0325e8dd731d71db11.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  ConsumerConfig:355 - The configuration 'client.id.prefix' was supplied but isn't a known config.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  ConsumerConfig:355 - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (7b0742ffe3b0734d0fe4b927167bdb2c) switched from CREATED to DEPLOYING.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (7b0742ffe3b0734d0fe4b927167bdb2c) [DEPLOYING].
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (a31c08da890178b9769fc6c6c5db656d), deploy into slot with allocation id a9dc4b9b6ad6ba0325e8dd731d71db11.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTableImpl:388 - Activate slot d99f887b9438786dc4c2e273b0225ab0.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (a31c08da890178b9769fc6c6c5db656d) switched from CREATED to DEPLOYING.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (a31c08da890178b9769fc6c6c5db656d) [DEPLOYING].
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (3e7390afd753fd9bcf3c3c5edae90c83), deploy into slot with allocation id d99f887b9438786dc4c2e273b0225ab0.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (3e7390afd753fd9bcf3c3c5edae90c83) switched from CREATED to DEPLOYING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTableImpl:388 - Activate slot d0f39bf079e2c8cd65d070496ac43b02.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (3e7390afd753fd9bcf3c3c5edae90c83) [DEPLOYING].
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:117 - Kafka version: 2.4.1
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:118 - Kafka commitId: c57222ae8cd7866b
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:119 - Kafka startTimeMs: 1649382608599
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (9e144a879b7d9f6a5167f4cde1948bc0), deploy into slot with allocation id d0f39bf079e2c8cd65d070496ac43b02.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (9e144a879b7d9f6a5167f4cde1948bc0) switched from CREATED to DEPLOYING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTableImpl:388 - Activate slot d99f887b9438786dc4c2e273b0225ab0.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTableImpl:388 - Activate slot 72a7c831a97bfff971a2834b23e2f16d.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AdminClientConfig:347 - AdminClientConfig values: 
	bootstrap.servers = [awnx1-cdata-tnode06:6667]
	client.dns.lookup = default
	client.id = g1-enumerator-admin-client
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTableImpl:388 - Activate slot d0f39bf079e2c8cd65d070496ac43b02.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (9e144a879b7d9f6a5167f4cde1948bc0) [DEPLOYING].
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTableImpl:388 - Activate slot 4f65c27498b35a4d694ad39f2282ea2c.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTableImpl:388 - Activate slot a9dc4b9b6ad6ba0325e8dd731d71db11.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTableImpl:388 - Activate slot 10020bd55fd6dadb00aac5166da0c55d.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTableImpl:388 - Activate slot f20ad3199712a0b550621ad098297c62.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTableImpl:388 - Activate slot 30a01b6251481ee86bf18331cc8831d5.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskSlotTableImpl:388 - Activate slot f20ad3199712a0b550621ad098297c62.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@65a605cc
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@438c050a
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@61800e0b
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@17197dc6
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@48abdd52
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@51d581c6
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@76ff9393
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@8717440
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  TaskExecutor:722 - Received task Sink: Collect table sink (1/1)#0 (fa5f264f0cfae7984306006ad0b43903), deploy into slot with allocation id f20ad3199712a0b550621ad098297c62.
2022-04-08 09:50:08 [Sink: Collect table sink (1/1)#0] INFO  Task:1067 - Sink: Collect table sink (1/1)#0 (fa5f264f0cfae7984306006ad0b43903) switched from CREATED to DEPLOYING.
2022-04-08 09:50:08 [Sink: Collect table sink (1/1)#0] INFO  Task:626 - Loading JAR files for task Sink: Collect table sink (1/1)#0 (fa5f264f0cfae7984306006ad0b43903) [DEPLOYING].
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (9e144a879b7d9f6a5167f4cde1948bc0) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (6de00c4fa80145ead101f7df10442201) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (6de74397c46488ed566a7525110163eb) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (a31c08da890178b9769fc6c6c5db656d) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (3e7390afd753fd9bcf3c3c5edae90c83) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (4e942d70fa065ea8c33886f95c9f8aa8) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [Sink: Collect table sink (1/1)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@2487fad2
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (950788f1f30d625eed1c6366a7c08e55) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (7b0742ffe3b0734d0fe4b927167bdb2c) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [Sink: Collect table sink (1/1)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:08 [Sink: Collect table sink (1/1)#0] INFO  Task:1067 - Sink: Collect table sink (1/1)#0 (fa5f264f0cfae7984306006ad0b43903) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (6de00c4fa80145ead101f7df10442201) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (9e144a879b7d9f6a5167f4cde1948bc0) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (6de74397c46488ed566a7525110163eb) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (a31c08da890178b9769fc6c6c5db656d) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (3e7390afd753fd9bcf3c3c5edae90c83) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (4e942d70fa065ea8c33886f95c9f8aa8) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (950788f1f30d625eed1c6366a7c08e55) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (7b0742ffe3b0734d0fe4b927167bdb2c) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (fa5f264f0cfae7984306006ad0b43903) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'key.deserializer' was supplied but isn't a known config.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'value.deserializer' was supplied but isn't a known config.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'group.id' was supplied but isn't a known config.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'client.id.prefix' was supplied but isn't a known config.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:117 - Kafka version: 2.4.1
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:118 - Kafka commitId: c57222ae8cd7866b
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:119 - Kafka startTimeMs: 1649382608661
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  KafkaSourceEnumerator:157 - Starting the KafkaSourceEnumerator for consumer group g1 without periodic partition discovery.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:50:08 [Sink: Collect table sink (1/1)#0] INFO  CollectSinkFunction:205 - Initializing collect sink state with offset = 0, buffered results bytes = 0
2022-04-08 09:50:08 [Sink: Collect table sink (1/1)#0] INFO  CollectSinkFunction:258 - Collect sink server established, address = localhost/127.0.0.1:64223
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-4] INFO  CollectSinkOperatorCoordinator:92 - Received sink socket server address: localhost/127.0.0.1:64223
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 2 @ 
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (950788f1f30d625eed1c6366a7c08e55) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (4e942d70fa065ea8c33886f95c9f8aa8) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (7b0742ffe3b0734d0fe4b927167bdb2c) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (9e144a879b7d9f6a5167f4cde1948bc0) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (3e7390afd753fd9bcf3c3c5edae90c83) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (a31c08da890178b9769fc6c6c5db656d) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 6 @ 
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (4e942d70fa065ea8c33886f95c9f8aa8) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 0 @ 
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (950788f1f30d625eed1c6366a7c08e55) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (6de74397c46488ed566a7525110163eb) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (7b0742ffe3b0734d0fe4b927167bdb2c) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 5 @ 
2022-04-08 09:50:08 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (6de00c4fa80145ead101f7df10442201) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (9e144a879b7d9f6a5167f4cde1948bc0) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 1 @ 
2022-04-08 09:50:08 [Sink: Collect table sink (1/1)#0] INFO  Task:1067 - Sink: Collect table sink (1/1)#0 (fa5f264f0cfae7984306006ad0b43903) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (3e7390afd753fd9bcf3c3c5edae90c83) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 4 @ 
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 3 @ 
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (a31c08da890178b9769fc6c6c5db656d) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:08 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 7 @ 
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (6de74397c46488ed566a7525110163eb) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (6de00c4fa80145ead101f7df10442201) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:08 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (fa5f264f0cfae7984306006ad0b43903) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:09 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])-worker-thread-1] INFO  TopicListSubscriber:68 - The following partitions have been added to the Kafka cluster. [test1-0]
2022-04-08 09:50:09 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  KafkaSourceEnumerator:299 - Assigning splits to readers {1=[[Partition: test1-0, StartingOffset: -1, StoppingOffset: -9223372036854775808]]}
2022-04-08 09:50:09 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SourceReaderBase:220 - Adding split(s) to reader: [[Partition: test1-0, StartingOffset: -1, StoppingOffset: -9223372036854775808]]
2022-04-08 09:50:09 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  ConsumerConfig:347 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [awnx1-cdata-tnode06:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = g1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = g1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-04-08 09:50:09 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] WARN  ConsumerConfig:355 - The configuration 'client.id.prefix' was supplied but isn't a known config.
2022-04-08 09:50:09 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] WARN  ConsumerConfig:355 - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2022-04-08 09:50:09 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  AppInfoParser:117 - Kafka version: 2.4.1
2022-04-08 09:50:09 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  AppInfoParser:118 - Kafka commitId: c57222ae8cd7866b
2022-04-08 09:50:09 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  AppInfoParser:119 - Kafka startTimeMs: 1649382609333
2022-04-08 09:50:09 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SplitFetcher:100 - Starting split fetcher 0
2022-04-08 09:50:09 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  KafkaConsumer:1123 - [Consumer clientId=g1-1, groupId=g1] Subscribed to partition(s): test1-0
2022-04-08 09:50:09 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SubscriptionState:564 - [Consumer clientId=g1-1, groupId=g1] Seeking to LATEST offset of partition test1-0
2022-04-08 09:50:09 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Metadata:259 - [Consumer clientId=g1-1, groupId=g1] Cluster ID: 5yVv1a4oRyO2KnAySdX1qw
2022-04-08 09:50:09 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SubscriptionState:381 - [Consumer clientId=g1-1, groupId=g1] Resetting offset for partition test1-0 to offset 114.
2022-04-08 09:50:50 [main] INFO  TypeExtractor:1991 - class java.util.LinkedHashMap does not contain a getter for field accessOrder
2022-04-08 09:50:50 [main] INFO  TypeExtractor:1994 - class java.util.LinkedHashMap does not contain a setter for field accessOrder
2022-04-08 09:50:50 [main] INFO  TypeExtractor:2037 - Class class java.util.LinkedHashMap cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2022-04-08 09:50:50 [main] INFO  TypeExtractor:2093 - class org.apache.flink.types.Row is missing a default constructor so it cannot be used as a POJO type and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2022-04-08 09:50:52 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
2022-04-08 09:50:52 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
2022-04-08 09:50:52 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
2022-04-08 09:50:52 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
2022-04-08 09:50:52 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
2022-04-08 09:50:52 [main] INFO  TaskExecutorResourceUtils:281 - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
2022-04-08 09:50:52 [main] INFO  MiniCluster:269 - Starting Flink Mini Cluster
2022-04-08 09:50:52 [main] INFO  MiniCluster:279 - Starting Metrics Registry
2022-04-08 09:50:52 [main] INFO  MetricRegistryImpl:126 - No metrics reporter configured, no metrics will be exposed/reported.
2022-04-08 09:50:52 [main] INFO  MiniCluster:283 - Starting RPC Service(s)
2022-04-08 09:50:52 [main] INFO  AkkaRpcServiceUtils:265 - Trying to start local actor system
2022-04-08 09:50:52 [flink-akka.actor.default-dispatcher-3] INFO  Slf4jLogger:92 - Slf4jLogger started
2022-04-08 09:50:52 [main] INFO  AkkaRpcServiceUtils:298 - Actor system started at akka://flink
2022-04-08 09:50:52 [main] INFO  AkkaRpcServiceUtils:265 - Trying to start local actor system
2022-04-08 09:50:52 [flink-metrics-2] INFO  Slf4jLogger:92 - Slf4jLogger started
2022-04-08 09:50:53 [main] INFO  AkkaRpcServiceUtils:298 - Actor system started at akka://flink-metrics
2022-04-08 09:50:53 [main] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2022-04-08 09:50:53 [main] INFO  MiniCluster:487 - Starting high-availability services
2022-04-08 09:50:54 [main] INFO  BlobServer:138 - Created BLOB server storage directory C:\Users\lixz\AppData\Local\Temp\blobStore-38ffd617-5440-4728-9e51-237d2f1ba1d7
2022-04-08 09:50:54 [main] INFO  BlobServer:213 - Started BLOB server at 0.0.0.0:64416 - max concurrent requests: 50 - max backlog: 1000
2022-04-08 09:50:54 [main] INFO  PermanentBlobCache:90 - Created BLOB cache storage directory C:\Users\lixz\AppData\Local\Temp\blobStore-0ae3cd35-26b2-4083-99b2-c23dbddce9a8
2022-04-08 09:50:54 [main] INFO  TransientBlobCache:90 - Created BLOB cache storage directory C:\Users\lixz\AppData\Local\Temp\blobStore-03e4c5ad-144e-49c1-99ff-9f4ca840d3dc
2022-04-08 09:50:54 [main] INFO  MiniCluster:606 - Starting 1 TaskManger(s)
2022-04-08 09:50:54 [main] INFO  TaskManagerRunner:474 - Starting TaskManager with ResourceID: 6dd51fa0-7ffc-4d14-abac-7437ede6fccb
2022-04-08 09:50:55 [main] INFO  TaskManagerServices:441 - Temporary file directory 'C:\Users\lixz\AppData\Local\Temp': total 119 GB, usable 10 GB (8.40% usable)
2022-04-08 09:50:55 [main] INFO  FileChannelManagerImpl:98 - FileChannelManager uses directory C:\Users\lixz\AppData\Local\Temp\flink-io-42101f09-ed02-4ec2-9d46-b85603df3509 for spill files.
2022-04-08 09:50:55 [main] INFO  FileChannelManagerImpl:98 - FileChannelManager uses directory C:\Users\lixz\AppData\Local\Temp\flink-netty-shuffle-a80b85ff-9d70-4de3-a3c7-d1b6d40c7398 for spill files.
2022-04-08 09:50:55 [main] INFO  NetworkBufferPool:145 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2022-04-08 09:50:55 [main] INFO  NettyShuffleEnvironment:328 - Starting the network environment and its components.
2022-04-08 09:50:55 [main] INFO  KvStateService:92 - Starting the kvState service and its components.
2022-04-08 09:50:55 [main] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2022-04-08 09:50:55 [flink-akka.actor.default-dispatcher-3] INFO  DefaultJobLeaderService:123 - Start job leader service.
2022-04-08 09:50:55 [flink-akka.actor.default-dispatcher-3] INFO  FileCache:116 - User file cache uses directory C:\Users\lixz\AppData\Local\Temp\flink-dist-cache-40c45769-1a74-48c9-8b77-13201c7b7eaf
2022-04-08 09:50:55 [main] INFO  DispatcherRestEndpoint:139 - Starting rest endpoint.
2022-04-08 09:50:55 [main] INFO  DispatcherRestEndpoint:126 - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2022-04-08 09:50:55 [main] WARN  WebMonitorUtils:82 - Log file environment variable 'log.file' is not set.
2022-04-08 09:50:55 [main] WARN  WebMonitorUtils:88 - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
2022-04-08 09:50:57 [main] INFO  DispatcherRestEndpoint:250 - Rest endpoint listening at localhost:64459
2022-04-08 09:50:57 [main] INFO  EmbeddedLeaderService:308 - Proposing leadership to contender http://localhost:64459
2022-04-08 09:50:57 [mini-cluster-io-thread-1] INFO  DispatcherRestEndpoint:994 - http://localhost:64459 was granted leadership with leaderSessionID=e8690754-61ab-4043-a2b2-141482554091
2022-04-08 09:50:57 [mini-cluster-io-thread-1] INFO  EmbeddedLeaderService:256 - Received confirmation of leadership for leader http://localhost:64459 , session=e8690754-61ab-4043-a2b2-141482554091
2022-04-08 09:50:57 [main] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
2022-04-08 09:50:57 [main] INFO  EmbeddedLeaderService:308 - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
2022-04-08 09:50:57 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:234 - Starting the resource manager.
2022-04-08 09:50:57 [mini-cluster-io-thread-2] INFO  DefaultDispatcherRunner:107 - DefaultDispatcherRunner was granted leadership with leader id 3cde48b2-e044-4514-a7d5-6744d84216c9. Creating new DispatcherLeaderProcess.
2022-04-08 09:50:57 [flink-akka.actor.default-dispatcher-3] INFO  EmbeddedLeaderService:308 - Proposing leadership to contender LeaderContender: StandaloneResourceManager
2022-04-08 09:50:57 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:1230 - ResourceManager akka://flink/user/rpc/resourcemanager_1 was granted leadership with fencing token 94868462d5faddd3b204a3b936a14788
2022-04-08 09:50:57 [main] INFO  MiniCluster:413 - Flink Mini Cluster started successfully
2022-04-08 09:50:57 [mini-cluster-io-thread-2] INFO  SessionDispatcherLeaderProcess:97 - Start SessionDispatcherLeaderProcess.
2022-04-08 09:50:57 [mini-cluster-io-thread-5] INFO  SessionDispatcherLeaderProcess:117 - Recover all persisted job graphs.
2022-04-08 09:50:57 [mini-cluster-io-thread-5] INFO  SessionDispatcherLeaderProcess:125 - Successfully recovered 0 persisted job graphs.
2022-04-08 09:50:57 [mini-cluster-io-thread-6] INFO  EmbeddedLeaderService:256 - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=b204a3b9-36a1-4788-9486-8462d5faddd3
2022-04-08 09:50:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1293 - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(94868462d5faddd3b204a3b936a14788).
2022-04-08 09:50:57 [mini-cluster-io-thread-5] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
2022-04-08 09:50:57 [mini-cluster-io-thread-5] INFO  EmbeddedLeaderService:256 - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=3cde48b2-e044-4514-a7d5-6744d84216c9
2022-04-08 09:50:57 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:162 - Resolved ResourceManager address, beginning registration
2022-04-08 09:50:57 [flink-akka.actor.default-dispatcher-6] INFO  StandaloneResourceManager:982 - Registering TaskManager with ResourceID 6dd51fa0-7ffc-4d14-abac-7437ede6fccb (akka://flink/user/rpc/taskmanager_0) at ResourceManager
2022-04-08 09:50:57 [flink-akka.actor.default-dispatcher-6] INFO  TaskExecutor:99 - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id 0e271b59cc82dff6efab97c26aa10b9b.
2022-04-08 09:50:57 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:300 - Received JobGraph submission 5a39b5c779dedda35840a2c6acbcf822 (collect).
2022-04-08 09:50:57 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneDispatcher:362 - Submitting job 5a39b5c779dedda35840a2c6acbcf822 (collect).
2022-04-08 09:50:57 [flink-akka.actor.default-dispatcher-4] INFO  EmbeddedLeaderService:308 - Proposing leadership to contender LeaderContender: JobMasterServiceLeadershipRunner
2022-04-08 09:50:57 [jobmanager-future-thread-1] INFO  AkkaRpcService:232 - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2022-04-08 09:50:57 [jobmanager-future-thread-1] INFO  JobMaster:289 - Initializing job collect (5a39b5c779dedda35840a2c6acbcf822).
2022-04-08 09:50:57 [jobmanager-future-thread-1] INFO  JobMaster:98 - Using restart back off time strategy NoRestartBackoffTimeStrategy for collect (5a39b5c779dedda35840a2c6acbcf822).
2022-04-08 09:50:58 [jobmanager-future-thread-1] INFO  JobMaster:159 - Running initialization on master for job collect (5a39b5c779dedda35840a2c6acbcf822).
2022-04-08 09:50:58 [jobmanager-future-thread-1] INFO  JobMaster:183 - Successfully ran initialization on master in 0 ms.
2022-04-08 09:50:58 [jobmanager-future-thread-1] INFO  DefaultExecutionTopology:271 - Built 1 pipelined regions in 2 ms
2022-04-08 09:50:58 [jobmanager-future-thread-1] INFO  JobMaster:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@15abe6d0
2022-04-08 09:50:58 [jobmanager-future-thread-1] INFO  JobMaster:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:58 [jobmanager-future-thread-1] INFO  CheckpointCoordinator:1532 - No checkpoint found during restore.
2022-04-08 09:50:58 [jobmanager-future-thread-1] INFO  JobMaster:145 - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@5f42fb6c for collect (5a39b5c779dedda35840a2c6acbcf822).
2022-04-08 09:50:58 [jobmanager-future-thread-1] INFO  EmbeddedLeaderService:256 - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=89169cec-3be2-4fd7-8b5b-cc10e8f4d5c3
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:867 - Starting execution of job collect (5a39b5c779dedda35840a2c6acbcf822) under job master id 8b5bcc10e8f4d5c389169cec3be24fd7.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  SourceCoordinator:113 - Starting split enumerator for source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]).
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:183 - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1039 - Job collect (5a39b5c779dedda35840a2c6acbcf822) switched from state CREATED to RUNNING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (a336b26ef4f065a57dfa4208dfbef54a) switched from CREATED to SCHEDULED.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (272f4a3453027a38931203b656405d01) switched from CREATED to SCHEDULED.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (d4ee6720522c52072bc5803b15d0dceb) switched from CREATED to SCHEDULED.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (04faee3d8cbb7b90597c9c77d0145f39) switched from CREATED to SCHEDULED.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (8ba00b4f64c09191dc7b47bed4e14c93) switched from CREATED to SCHEDULED.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (fc297fca236a77bc84340c6ed28b79e4) switched from CREATED to SCHEDULED.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (f1e75e23048c2eab50a086e1d58f9f6e) switched from CREATED to SCHEDULED.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (179bb5507e177311e86fe687a796ad24) switched from CREATED to SCHEDULED.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (2f18f08809459c32a239dd52e5699038) switched from CREATED to SCHEDULED.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:1040 - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(94868462d5faddd3b204a3b936a14788)
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  JobMaster:162 - Resolved ResourceManager address, beginning registration
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  StandaloneResourceManager:355 - Registering job manager 8b5bcc10e8f4d5c389169cec3be24fd7@akka://flink/user/rpc/jobmanager_3 for job 5a39b5c779dedda35840a2c6acbcf822.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  ConsumerConfig:347 - ConsumerConfig values: 
	allow.auto.create.topics = false
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [awnx1-cdata-tnode06:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = g1-enumerator-consumer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = g1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  StandaloneResourceManager:909 - Registered job manager 8b5bcc10e8f4d5c389169cec3be24fd7@akka://flink/user/rpc/jobmanager_3 for job 5a39b5c779dedda35840a2c6acbcf822.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  JobMaster:1064 - JobManager successfully registered at ResourceManager, leader id: 94868462d5faddd3b204a3b936a14788.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  DeclarativeSlotManager:263 - Received resource requirements from job 5a39b5c779dedda35840a2c6acbcf822: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=8}]
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1027 - Receive slot request 0bc5b38155499315a923a8941378cb3f for job 5a39b5c779dedda35840a2c6acbcf822 from resource manager with leader id 94868462d5faddd3b204a3b936a14788.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1104 - Allocated slot for 0bc5b38155499315a923a8941378cb3f.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  DefaultJobLeaderService:188 - Add job 5a39b5c779dedda35840a2c6acbcf822 for job leader monitoring.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1027 - Receive slot request f48a981bbd225e3b4cdc3c1458e6fe13 for job 5a39b5c779dedda35840a2c6acbcf822 from resource manager with leader id 94868462d5faddd3b204a3b936a14788.
2022-04-08 09:50:58 [mini-cluster-io-thread-17] INFO  DefaultJobLeaderService:346 - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id 89169cec-3be2-4fd7-8b5b-cc10e8f4d5c3.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1104 - Allocated slot for f48a981bbd225e3b4cdc3c1458e6fe13.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1027 - Receive slot request 462879fe90a849730dd4166130bac8ce for job 5a39b5c779dedda35840a2c6acbcf822 from resource manager with leader id 94868462d5faddd3b204a3b936a14788.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1104 - Allocated slot for 462879fe90a849730dd4166130bac8ce.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  DefaultJobLeaderService:162 - Resolved JobManager address, beginning registration
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1027 - Receive slot request 3096be977e360c2e268b9dc37dc7454b for job 5a39b5c779dedda35840a2c6acbcf822 from resource manager with leader id 94868462d5faddd3b204a3b936a14788.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1104 - Allocated slot for 3096be977e360c2e268b9dc37dc7454b.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1027 - Receive slot request f0aba5b073c338a28d0a62d77e79119b for job 5a39b5c779dedda35840a2c6acbcf822 from resource manager with leader id 94868462d5faddd3b204a3b936a14788.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1104 - Allocated slot for f0aba5b073c338a28d0a62d77e79119b.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1027 - Receive slot request 7aad2af1c6e0d901f29ac7b59516d25d for job 5a39b5c779dedda35840a2c6acbcf822 from resource manager with leader id 94868462d5faddd3b204a3b936a14788.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1104 - Allocated slot for 7aad2af1c6e0d901f29ac7b59516d25d.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1027 - Receive slot request b04ffbadcbc62bedd8767555f6d70651 for job 5a39b5c779dedda35840a2c6acbcf822 from resource manager with leader id 94868462d5faddd3b204a3b936a14788.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1104 - Allocated slot for b04ffbadcbc62bedd8767555f6d70651.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1027 - Receive slot request ed8984d9e708342a97fa432e8f46ff2f for job 5a39b5c779dedda35840a2c6acbcf822 from resource manager with leader id 94868462d5faddd3b204a3b936a14788.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1104 - Allocated slot for ed8984d9e708342a97fa432e8f46ff2f.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  DefaultJobLeaderService:413 - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job 5a39b5c779dedda35840a2c6acbcf822.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1608 - Establish JobManager connection for job 5a39b5c779dedda35840a2c6acbcf822.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:1459 - Offer reserved slots to the leader of job 5a39b5c779dedda35840a2c6acbcf822.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (a336b26ef4f065a57dfa4208dfbef54a) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (attempt #0) with attempt id a336b26ef4f065a57dfa4208dfbef54a to 6dd51fa0-7ffc-4d14-abac-7437ede6fccb @ 127.0.0.1 (dataPort=-1) with allocation id 7aad2af1c6e0d901f29ac7b59516d25d
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (272f4a3453027a38931203b656405d01) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 7aad2af1c6e0d901f29ac7b59516d25d.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (attempt #0) with attempt id 272f4a3453027a38931203b656405d01 to 6dd51fa0-7ffc-4d14-abac-7437ede6fccb @ 127.0.0.1 (dataPort=-1) with allocation id 0bc5b38155499315a923a8941378cb3f
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (d4ee6720522c52072bc5803b15d0dceb) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (attempt #0) with attempt id d4ee6720522c52072bc5803b15d0dceb to 6dd51fa0-7ffc-4d14-abac-7437ede6fccb @ 127.0.0.1 (dataPort=-1) with allocation id 3096be977e360c2e268b9dc37dc7454b
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (04faee3d8cbb7b90597c9c77d0145f39) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (attempt #0) with attempt id 04faee3d8cbb7b90597c9c77d0145f39 to 6dd51fa0-7ffc-4d14-abac-7437ede6fccb @ 127.0.0.1 (dataPort=-1) with allocation id ed8984d9e708342a97fa432e8f46ff2f
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (8ba00b4f64c09191dc7b47bed4e14c93) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (attempt #0) with attempt id 8ba00b4f64c09191dc7b47bed4e14c93 to 6dd51fa0-7ffc-4d14-abac-7437ede6fccb @ 127.0.0.1 (dataPort=-1) with allocation id b04ffbadcbc62bedd8767555f6d70651
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (fc297fca236a77bc84340c6ed28b79e4) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (attempt #0) with attempt id fc297fca236a77bc84340c6ed28b79e4 to 6dd51fa0-7ffc-4d14-abac-7437ede6fccb @ 127.0.0.1 (dataPort=-1) with allocation id 462879fe90a849730dd4166130bac8ce
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (f1e75e23048c2eab50a086e1d58f9f6e) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (attempt #0) with attempt id f1e75e23048c2eab50a086e1d58f9f6e to 6dd51fa0-7ffc-4d14-abac-7437ede6fccb @ 127.0.0.1 (dataPort=-1) with allocation id f48a981bbd225e3b4cdc3c1458e6fe13
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (179bb5507e177311e86fe687a796ad24) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:571 - Deploying Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (attempt #0) with attempt id 179bb5507e177311e86fe687a796ad24 to 6dd51fa0-7ffc-4d14-abac-7437ede6fccb @ 127.0.0.1 (dataPort=-1) with allocation id f0aba5b073c338a28d0a62d77e79119b
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (2f18f08809459c32a239dd52e5699038) switched from SCHEDULED to DEPLOYING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:571 - Deploying Sink: Collect table sink (1/1) (attempt #0) with attempt id 2f18f08809459c32a239dd52e5699038 to 6dd51fa0-7ffc-4d14-abac-7437ede6fccb @ 127.0.0.1 (dataPort=-1) with allocation id 7aad2af1c6e0d901f29ac7b59516d25d
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (a336b26ef4f065a57dfa4208dfbef54a), deploy into slot with allocation id 7aad2af1c6e0d901f29ac7b59516d25d.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  ConsumerConfig:355 - The configuration 'client.id.prefix' was supplied but isn't a known config.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (a336b26ef4f065a57dfa4208dfbef54a) switched from CREATED to DEPLOYING.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  ConsumerConfig:355 - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 0bc5b38155499315a923a8941378cb3f.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (272f4a3453027a38931203b656405d01), deploy into slot with allocation id 0bc5b38155499315a923a8941378cb3f.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (a336b26ef4f065a57dfa4208dfbef54a) [DEPLOYING].
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 3096be977e360c2e268b9dc37dc7454b.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (272f4a3453027a38931203b656405d01) switched from CREATED to DEPLOYING.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (272f4a3453027a38931203b656405d01) [DEPLOYING].
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (d4ee6720522c52072bc5803b15d0dceb), deploy into slot with allocation id 3096be977e360c2e268b9dc37dc7454b.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot ed8984d9e708342a97fa432e8f46ff2f.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (d4ee6720522c52072bc5803b15d0dceb) switched from CREATED to DEPLOYING.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:117 - Kafka version: 2.4.1
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:118 - Kafka commitId: c57222ae8cd7866b
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (d4ee6720522c52072bc5803b15d0dceb) [DEPLOYING].
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:119 - Kafka startTimeMs: 1649382658246
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (04faee3d8cbb7b90597c9c77d0145f39), deploy into slot with allocation id ed8984d9e708342a97fa432e8f46ff2f.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AdminClientConfig:347 - AdminClientConfig values: 
	bootstrap.servers = [awnx1-cdata-tnode06:6667]
	client.dns.lookup = default
	client.id = g1-enumerator-admin-client
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot b04ffbadcbc62bedd8767555f6d70651.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (04faee3d8cbb7b90597c9c77d0145f39) switched from CREATED to DEPLOYING.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (04faee3d8cbb7b90597c9c77d0145f39) [DEPLOYING].
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (8ba00b4f64c09191dc7b47bed4e14c93), deploy into slot with allocation id b04ffbadcbc62bedd8767555f6d70651.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 462879fe90a849730dd4166130bac8ce.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (8ba00b4f64c09191dc7b47bed4e14c93) switched from CREATED to DEPLOYING.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (8ba00b4f64c09191dc7b47bed4e14c93) [DEPLOYING].
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (fc297fca236a77bc84340c6ed28b79e4), deploy into slot with allocation id 462879fe90a849730dd4166130bac8ce.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot f48a981bbd225e3b4cdc3c1458e6fe13.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (fc297fca236a77bc84340c6ed28b79e4) switched from CREATED to DEPLOYING.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (fc297fca236a77bc84340c6ed28b79e4) [DEPLOYING].
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (f1e75e23048c2eab50a086e1d58f9f6e), deploy into slot with allocation id f48a981bbd225e3b4cdc3c1458e6fe13.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (f1e75e23048c2eab50a086e1d58f9f6e) switched from CREATED to DEPLOYING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot f0aba5b073c338a28d0a62d77e79119b.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (f1e75e23048c2eab50a086e1d58f9f6e) [DEPLOYING].
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (179bb5507e177311e86fe687a796ad24), deploy into slot with allocation id f0aba5b073c338a28d0a62d77e79119b.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 7aad2af1c6e0d901f29ac7b59516d25d.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (179bb5507e177311e86fe687a796ad24) switched from CREATED to DEPLOYING.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:626 - Loading JAR files for task Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (179bb5507e177311e86fe687a796ad24) [DEPLOYING].
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6c1381cb
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@23477ab5
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@347ad12e
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3ce7f329
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@5b3914fa
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@5cdd276b
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@13c085fe
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@5c0aaad3
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskExecutor:722 - Received task Sink: Collect table sink (1/1)#0 (2f18f08809459c32a239dd52e5699038), deploy into slot with allocation id 7aad2af1c6e0d901f29ac7b59516d25d.
2022-04-08 09:50:58 [Sink: Collect table sink (1/1)#0] INFO  Task:1067 - Sink: Collect table sink (1/1)#0 (2f18f08809459c32a239dd52e5699038) switched from CREATED to DEPLOYING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot f48a981bbd225e3b4cdc3c1458e6fe13.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'key.deserializer' was supplied but isn't a known config.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot f0aba5b073c338a28d0a62d77e79119b.
2022-04-08 09:50:58 [Sink: Collect table sink (1/1)#0] INFO  Task:626 - Loading JAR files for task Sink: Collect table sink (1/1)#0 (2f18f08809459c32a239dd52e5699038) [DEPLOYING].
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'value.deserializer' was supplied but isn't a known config.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 0bc5b38155499315a923a8941378cb3f.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'group.id' was supplied but isn't a known config.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'client.id.prefix' was supplied but isn't a known config.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 7aad2af1c6e0d901f29ac7b59516d25d.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] WARN  AdminClientConfig:355 - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 462879fe90a849730dd4166130bac8ce.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:117 - Kafka version: 2.4.1
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:118 - Kafka commitId: c57222ae8cd7866b
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  AppInfoParser:119 - Kafka startTimeMs: 1649382658324
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot b04ffbadcbc62bedd8767555f6d70651.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot 3096be977e360c2e268b9dc37dc7454b.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  TaskSlotTableImpl:388 - Activate slot ed8984d9e708342a97fa432e8f46ff2f.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (d4ee6720522c52072bc5803b15d0dceb) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (fc297fca236a77bc84340c6ed28b79e4) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [Sink: Collect table sink (1/1)#0] INFO  StreamTask:300 - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@64cf87a8
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (272f4a3453027a38931203b656405d01) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  KafkaSourceEnumerator:157 - Starting the KafkaSourceEnumerator for consumer group g1 without periodic partition discovery.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (04faee3d8cbb7b90597c9c77d0145f39) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (f1e75e23048c2eab50a086e1d58f9f6e) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (8ba00b4f64c09191dc7b47bed4e14c93) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (179bb5507e177311e86fe687a796ad24) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [Sink: Collect table sink (1/1)#0] INFO  StreamTask:274 - Checkpoint storage is set to 'jobmanager'
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (a336b26ef4f065a57dfa4208dfbef54a) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [Sink: Collect table sink (1/1)#0] INFO  Task:1067 - Sink: Collect table sink (1/1)#0 (2f18f08809459c32a239dd52e5699038) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (d4ee6720522c52072bc5803b15d0dceb) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (fc297fca236a77bc84340c6ed28b79e4) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (272f4a3453027a38931203b656405d01) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (04faee3d8cbb7b90597c9c77d0145f39) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (f1e75e23048c2eab50a086e1d58f9f6e) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (179bb5507e177311e86fe687a796ad24) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (8ba00b4f64c09191dc7b47bed4e14c93) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (a336b26ef4f065a57dfa4208dfbef54a) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-3] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (2f18f08809459c32a239dd52e5699038) switched from DEPLOYING to INITIALIZING.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] WARN  MetricGroup:154 - The operator name DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) exceeded the 80 characters length limit and was truncated.
2022-04-08 09:50:58 [Sink: Collect table sink (1/1)#0] INFO  CollectSinkFunction:205 - Initializing collect sink state with offset = 0, buffered results bytes = 0
2022-04-08 09:50:58 [Sink: Collect table sink (1/1)#0] INFO  CollectSinkFunction:258 - Collect sink server established, address = localhost/127.0.0.1:64465
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-4] INFO  CollectSinkOperatorCoordinator:92 - Received sink socket server address: localhost/127.0.0.1:64465
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8)#0 (8ba00b4f64c09191dc7b47bed4e14c93) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8)#0 (fc297fca236a77bc84340c6ed28b79e4) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8)#0 (179bb5507e177311e86fe687a796ad24) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8)#0 (f1e75e23048c2eab50a086e1d58f9f6e) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (5/8) (8ba00b4f64c09191dc7b47bed4e14c93) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8)#0 (04faee3d8cbb7b90597c9c77d0145f39) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (6/8) (fc297fca236a77bc84340c6ed28b79e4) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 2 @ 
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (8/8) (179bb5507e177311e86fe687a796ad24) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8)#0 (a336b26ef4f065a57dfa4208dfbef54a) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (7/8) (f1e75e23048c2eab50a086e1d58f9f6e) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 0 @ 
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (4/8) (04faee3d8cbb7b90597c9c77d0145f39) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (1/8) (a336b26ef4f065a57dfa4208dfbef54a) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0 (272f4a3453027a38931203b656405d01) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0] INFO  Task:1067 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8)#0 (d4ee6720522c52072bc5803b15d0dceb) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 4 @ 
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 5 @ 
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8) (272f4a3453027a38931203b656405d01) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 1 @ 
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (3/8) (d4ee6720522c52072bc5803b15d0dceb) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 7 @ 
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 3 @ 
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  SourceCoordinator:186 - Source Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) registering reader for parallel task 6 @ 
2022-04-08 09:50:58 [Sink: Collect table sink (1/1)#0] INFO  Task:1067 - Sink: Collect table sink (1/1)#0 (2f18f08809459c32a239dd52e5699038) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [flink-akka.actor.default-dispatcher-2] INFO  ExecutionGraph:1438 - Sink: Collect table sink (1/1) (2f18f08809459c32a239dd52e5699038) switched from INITIALIZING to RUNNING.
2022-04-08 09:50:58 [collect-sink-operator-coordinator-executor-thread-pool-thread-1] INFO  CollectSinkOperatorCoordinator:134 - Sink connection established
2022-04-08 09:50:58 [Thread-7] INFO  CollectSinkFunction:388 - Coordinator connection received
2022-04-08 09:50:58 [Thread-7] INFO  CollectSinkFunction:409 - Invalid request. Received version = , offset = 0, while expected version = 7b049463-5f84-4192-abb0-b883dc788bc9, offset = 0
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])-worker-thread-1] INFO  TopicListSubscriber:68 - The following partitions have been added to the Kafka cluster. [test1-0]
2022-04-08 09:50:58 [SourceCoordinator-Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name])] INFO  KafkaSourceEnumerator:299 - Assigning splits to readers {1=[[Partition: test1-0, StartingOffset: -1, StoppingOffset: -9223372036854775808]]}
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SourceReaderBase:220 - Adding split(s) to reader: [[Partition: test1-0, StartingOffset: -1, StoppingOffset: -9223372036854775808]]
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  ConsumerConfig:347 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [awnx1-cdata-tnode06:6667]
	check.crcs = true
	client.dns.lookup = default
	client.id = g1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = g1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] WARN  ConsumerConfig:355 - The configuration 'client.id.prefix' was supplied but isn't a known config.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] WARN  ConsumerConfig:355 - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  AppInfoParser:117 - Kafka version: 2.4.1
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  AppInfoParser:118 - Kafka commitId: c57222ae8cd7866b
2022-04-08 09:50:58 [Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  AppInfoParser:119 - Kafka startTimeMs: 1649382658971
2022-04-08 09:50:58 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SplitFetcher:100 - Starting split fetcher 0
2022-04-08 09:50:58 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  KafkaConsumer:1123 - [Consumer clientId=g1-1, groupId=g1] Subscribed to partition(s): test1-0
2022-04-08 09:50:58 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SubscriptionState:564 - [Consumer clientId=g1-1, groupId=g1] Seeking to LATEST offset of partition test1-0
2022-04-08 09:50:59 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  Metadata:259 - [Consumer clientId=g1-1, groupId=g1] Cluster ID: 5yVv1a4oRyO2KnAySdX1qw
2022-04-08 09:50:59 [Source Data Fetcher for Source: kafka-source -> Flat Map -> DataSteamToTable(stream=default_catalog.default_database.Unregistered_DataStream_Source_2, type=ROW<`f0` INT, `f1` STRING, `f2` DOUBLE> NOT NULL, rowtime=false, watermark=false) -> Calc(select=[f0 AS id, f1 AS name, f2 AS pay]) -> NotNullEnforcer(fields=[name]) (2/8)#0] INFO  SubscriptionState:381 - [Consumer clientId=g1-1, groupId=g1] Resetting offset for partition test1-0 to offset 116.
